---
title: "[![](./images/lindens.jpg)](https://en.wikipedia.org/wiki/Clumber_Park) Applying LIME to a Random Forest Model"
author: Katherine Goode
date: ISU Graphics Group <div style="margin-bottom:100px;"> March 1, 2019
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

# Overview

.pull-left[
### Goals for the talk
- Explain the LIME algorithm
- Present an application of LIME
- Highlight problems with this application

### The plan

1. Explanation of LIME 
2. Hamby bullet data
3. Applying LIME to the bullet data
4. Issues with LIME
5. Attempts at a solution
6. Future work
]

.pull-right[
<br>
<br>
<img src="./images/lime_drawing.png" width = 400>
]

---

class: inverse, center, middle

# What is <span style="color:lime">LIME</span>?

---

# Motivation for LIME

<br>

[![](./images/blackbox.png)](https://en.wikipedia.org/wiki/Black_box)

### Black Box Prediction Models

- Offer great predictive ability 
- Loss of interpretability
- Difficult to assess trustworthiness

### Enter LIME

- **L**ocal **I**nterpretable **M**odel-Agnostic **E**xplanations
- Developed by computer scientists ([Ribeiro, Singh, and Guestrin](https://arxiv.org/pdf/1602.04938.pdf))
- Designed to assess if a black box predictive model is trustworthy
- Produces "explanations" for individual predictions

---

# Meaning of LIME

.pull-left[
### <span style="color:lime">L</span>ocal

- Focuses on behavior of a complex model at a local level

### <span style="color:lime">I</span>nterpretable

- Produces easily interpretable "explanations"

### <span style="color:lime">M</span>odel-Agnostic

- Works with any black-box predictor

### <span style="color:lime">E</span>xplanations

- Provides insight into individual predictions
]

.pull-right[
<br>
<br>
.center[<img src="./images/local.png" width=300>]
.center[<font size="4">Figure 3 in Ribeiro, Singh, and Guestrin (2016)</font>]
<br>
<br>
.center[<img src="./images/image_explanation.png" width=500>]
.center[<font size="4">Figure 4 in Ribeiro, Singh, and Guestrin (2016)</font>]
]


---

# An Example <font size="3">(from Ribeiro, Singh, and Guestrin (2016))</font>

.pull-left[
### 1. Black Box Model 
- Model predicts whether a patient has the flu
- Apply the model to a new patient
- Predicts that the patient has the flu
- Can this prediction be trusted?
]

.pull-right[
### 2. LIME
- Apply LIME to *this* case
- LIME returns the most important variables in *this* prediction
- Colors indicate
    + <span style="color:green">green</span>: evidence supporting the flu
    + <span style="color:red">red</span>: evidence against the flu
- Can this prediction be trusted?
]

.center[<img src="./images/example.png" width=700>]
.center[<font size="4">Figure 1 in Ribeiro, Singh, and Guestrin (2016)</font>]
 
---

# Using LIME

### Implementations of LIME

- Developers created a Python package
- Thomas Pedersen created an R package called lime

![](./images/lime.png)

---

class: inverse, center, middle

# Hamby Bullet Matching Data

---
class: inverse, center, middle

# Applying LIME to the bullet data

---
class: inverse, center, middle

# Issues with LIME

---
class: inverse, center, middle

# Attempts at a Solution

---
class: inverse, center, middle

# Future Work
