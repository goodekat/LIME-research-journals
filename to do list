
-------------
TO DO LIST
-------------

Goals for spring semester:
- implement ideas for better binning methods
- find an idea that leads to better LIME explanations
- write firearm examiner's paper
- make plans for the statistical paper

Questions:
- I've been thinking about how to know if lime is really grasping the nature 
  of the random forest. Should I try implementing Urbanek's visualizations to 
  "see" if the lime results make sense, or is there something else I could do 
  to really know if lime is doing a good job?

Completed:
- run sensativity analysis with rfscore
- clean up code after sensativity analysis
- write an abstract draft for JSM
- computed kappa for sensativity analysis

Current:
- add rfscore to code where I create the training data and add this code to this project
- seriation: https://cran.r-project.org/web/packages/seriation/vignettes/seriation.pdf
- write up paragraph of 
- read through Heike's new function
- think of a way to compute consistency across top two features
- compare the simple models based on different number of bins using an F-test
- look into literature on binning methods
- think about why R^2 would be better for some binning methods
- look into computing a diversity or consistency measure for the sensitivity analysis
- create distribution visualizations bins
- include a penalty for the number of parameters when choosing bins

Later:
- determine the best number of bins to use for each variable
- look at the AUC after binning
- write a draft of the examiners paper
- try out different weights
- read through LIME papers again
- compute a likelihood ratio prob TRUE / prob FALSE from the LIME ridge regression
- try out logistic regression idea for bins (write own bin list to put in explain)
- try out subsampling idea
- read new paper on Anchor
- read book Dr. Dixon lent me
- try visualizing the features from the test data using dimension reduction and
  coloring them by variables suggested to be important by lime
- look into papers by Giles Hooker and Lucas Mentch
