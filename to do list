
-------------
TO DO LIST
-------------

Questions:

Thoughts:

Completed:

Current:
- think about the fact that we want to choose an option that leads to consistent results
- choose a model that is good - not necessarily the best
- look into "future" and "furrr" packages that are good for improving computation speed
- deal with the warnings that appear in between the switches in app
  - put in a check for a dataset then proceed or do nothing
- look into a conditional panel in Shiny for simple vs complicated app
- adjust app to use both full and subsampled
- fix problem with app due to bins with the non-bin cases
- check on sampling variability (run each lime implementation several times)
- add distribution visualizations to the app with the chosen bins
- color bin text in the table
- read through LIME papers again
- try out logistic regression idea for bins (write own bin list to put in explain)
- paper
  - ask Ganesh for his explanations of the features
  - need to clean up the section on the description of LIME (better notation and explanation)
  - add the section on the random forest as well to have a starting point for the notation
  - finish a draft of the introduction to the paper
  - write about the training data
  - make list of features and describe them
  - write definitions of what LIME outputs
- compute a likelihood ratio prob TRUE / prob FALSE from the LIME ridge regression

Later:
- read new paper on Anchor
- read book Dr. Dixon lent me
- try visualizing the features from the test data using dimension reduction and
  coloring them by variables suggested to be important by lime
- look into papers by Giles Hooker and Lucas Mentch