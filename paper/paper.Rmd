---
title: "Interpreting Random Forest Predictions for Firearm Identification Using LIME"
author: "Katherine Goode and Heike Hofmann"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  pdf_document:
    number_sections: true
bibliography: references.bib
---

```{r setup, include = FALSE}
# Set knitr options
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, cache = TRUE)

# Load libraries
library(tidyverse)
library(bulletr)
library(lime)
library(randomForest)
```

# Introduction

(need to finish adding sources)

The discipline of firearm identification examines bullets to determine the likelihood that a bullet found in a criminal case was fired from a particular gun. To do this, the bullet from the crime will be compared with a bullet that was known to be fired from the gun under evaluation. Traditionally, this is a procedure that has been performed by hand. Specially trained examiners visually compare the microscopic bullet striations that were created when the bullets passed through the gun barrel. Often a comparison microscope is used that allows the examiners to view both bullets at the same time (National Research Council 2009). The examiners use this ability to determine whether the two bullets were fired from the same gun barrel.

Recently, the scientific community has been encouraging the inclusion of more data driven techniques to be used in forensic investigations. These methods would allow for the reporting of a measure of uncertainty in addition to the conclusion drawn from the analysis. This led Hare, Hofmann, and Carriquiry (2017) to propose a new computer automated method of bullet matching that could supplement the visual inspection by the firearm examiners. Their method involves obtaining bullet signatures of the striations from the scans of the two bullets, computing variables that measure the similarity of the two signatures, and using a trained random forest model to determine the probability of a match based on the similarity variables. They trained their model on a set of known bullet matches and non-matches from the Hamby study. They demonstrated how the random forest model can be used to make prediction on a new set of bullet signature comparisons. The results from the paper suggest that the random forest model leads to highly accurate bullet matching predictions. The authors found that when their model was applied to a testing dataset (?), the resulting error rate was 0%.

While random forest models often result in good predictions as seen in Hare, Hofmann, and Carriquiry, it is well known that a disadvantage of random forest models and other machine learning techniques is that it is difficult to interpret the models (reference?). For example, it is not possible to tell which variables played an important role in the creation of individual predictions. This issue led to the development of LIME (reference), which is an algorithm that examines the behavior of the complicated model on a local scale around a new prediction using a linear regression model. This allows for the ability to understand which were the driving variables that led to a prediction of interest.

Since firearm identification identification is commonly used as evidence for convictions in court cases, it is important to be able to understand and assess the model that is being used to quantify the probability that a bullet was fired from a gun. LIME provides the ability to understand which were the key variables used by the random forest model to make a prediction, which would allow firearm examiners to check whether or not the predictions created by the random forest are based on reasonable variables. 

This paper provides an example of the application of LIME to a bullet matching problem. (provide more details about what is contained in the papers - i.e. section 2 describes the Hamby data; section 3 describes the random forest model and LIME; ...)

# Data

## Training Data: The Hamby...

(fill in once we know which data will be used to train the new random forest model)

```{r}
# Load in the training data (Hamby Data 173 and 252)
hamby173and252_train <- read.csv("../data/hamby173and252_train.csv")
```

## Testing Data: The Hamby 224 Clone

The Hamby 224 Clone is organized as a test set of a cloned (sub-)set of the Hamby 224 bullets. As with all Hamby sets [@hamby], Hamby set 224, is a collection of 35 bullets, organized as 20 known bullets and 15 questioned bullets. The known bullets are fired in pairs of two through one of ten consecutively manufactures P-85 barrels.
Clone set 224 is arranged as a test set of fifteen tests, one for each questioned bullet. Each test set is arranged as a combination of three bullets: two known bullets and a questioned bullet. The test asks for a decision on whether the questioned bullet comes from the same source as the two known bullets  or from a different source. This situation is similar to what a Firearms and Toolmarks Examiner might encounter in case work. 

```{r}
# Load in the Hamby 224 datasets
hamby224_set1 <- readRDS("../data/h224-set1-features.rds")
hamby224_set11 <- readRDS("../data/h224-set11-features.rds")
```

```{r}
# Obtain features used when fitting the rtrees random forest
rf_features <- rownames(rtrees$importance)

# Clean the Hamby 224 set 1 data
hamby224_set1_cleaned <- hamby224_set1 %>%
  select(-bullet_score, -land1, -land2, -aligned, -striae, -features) %>%
  rename(bullet1 = bulletA,
         bullet2 = bulletB, 
         land1 = landA,
         land2 = landB) %>%
  mutate(study = factor("Hamby_224"), 
         set = factor("1"),
         bullet1 = factor(bullet1),
         bullet2 = factor(bullet2),
         land1 = factor(land1),
         land2 = factor(land2)) %>%
  select(study, set, bullet1:land2, rf_features, rfscore, samesource)

# Clean the Hamby 224 set 11 data
hamby224_set11_cleaned <- hamby224_set11 %>%
  select(-bullet_score, -land1, -land2, -aligned, -striae, -features) %>%
  rename(bullet1 = bulletA,
         bullet2 = bulletB, 
         land1 = landA,
         land2 = landB) %>%
  mutate(study = factor("Hamby_224"), 
         set = factor("11"),
         bullet1 = recode(factor(bullet1), 
                          "Bullet 1" = "1", 
                          "Bullet 2" = "2", 
                          "Bullet I" = "I"),
         bullet2 = recode(factor(bullet2), 
                          "Bullet 1" = "1", 
                          "Bullet 2" = "2", 
                          "Bullet I" = "I"),
         land1 = recode(factor(land1), 
                        "Land 1" = "1", "Land 2" = "2", "Land 3" = "3", 
                        "Land 4" = "4", "Land 5" = "5", "Land 6" = "6"),
         land2 = recode(factor(land2), 
                        "Land 1" = "1", "Land 2" = "2", "Land 3" = "3", 
                        "Land 4" = "4", "Land 5" = "5", "Land 6" = "6")) %>%
  select(study, set, bullet1:land2, rf_features, rfscore, samesource)

# Join the two cleaned Hamby 224 sets into one testing set
hamby224_test <- suppressWarnings(bind_rows(hamby224_set1_cleaned,
                                            hamby224_set11_cleaned))

# Save the test data as a .csv file
write.csv(hamby224_test, "../data/hamby224_test.csv", row.names = FALSE)
```

#  Methods

## Random Forest Model

(fill in once the new random forest model has been fit)

## Overview of LIME

## Applying LIME

```{r echo = FALSE}
# Apply the lime function from the lime package (with a seed set)
# Note that the as_classifier must be added since rtrees is from the
# randomForest package and not fit using caret or one of the other 
# available models specified in the lime package. Additionally, the
# randomForest package must be loaded in order to run the functions
# from the lime package. (I should check on exactly how this works.)
set.seed(84902)
hamby224_lime <- lime(x = hamby173and252_train %>% select(rf_features),
                      model = as_classifier(rtrees))

# Save the lime object
saveRDS(hamby224_lime, "../data/hamby224_lime.rds")
```

```{r}
# Apply the explain function from the lime package (with a seed set)
set.seed(84902)
hamby224_explain <- lime::explain(hamby224_test %>% select(rf_features), 
                                  hamby224_lime, 
                                  n_labels = 1, 
                                  n_features = 3)

# Save the explainer object
saveRDS(hamby224_explain, "../data/hamby224_explain.rds")
```

```{r echo = FALSE}
# Add a case variable to the test data
hamby224_test <- hamby224_test %>%
  mutate(case = as.character(1:dim(hamby224_test)[1])) %>%
  select(case, study:samesource)

# Obtain features used when fitting the rtrees random forest
rf_features <- rownames(rtrees$importance)

# Join the data and the explanations and edit and add additional variables
hamby224_test_explain <- full_join(hamby224_test, hamby224_explain, by = "case") %>%
  mutate(case = factor(case),
         set = factor(set),
         bullet1 = factor(bullet1),
         bullet2 = factor(bullet2),
         land1 = factor(land1),
         land2 = factor(land2)) %>%
  mutate(mypred = rep(predict(rtrees, hamby224_test %>% select(rf_features), 
                              type = "prob")[,2], each = 3)) %>%
  select(case:rfscore, mypred, samesource:prediction) %>%
  mutate(feature_desc = factor(feature_desc),
         feature = factor(feature)) %>%
  mutate(feature_number = readr::parse_number(feature_desc),
         strictly_less = FALSE)

# Finish creating the strictly less than variable
hamby224_test_explain$strictly_less[grep("< ", hamby224_test_explain$feature_desc)] <- TRUE

# Reorder the variable of feature_desc for plotting purposes
hamby224_test_explain <- hamby224_test_explain %>%
  mutate(
    feature_desc = reorder(feature_desc, strictly_less),
    feature_desc = reorder(feature_desc, feature_number),
    feature_desc = reorder(feature_desc, as.numeric(feature))
  )

# Save the combined test and explain data
saveRDS(hamby224_test_explain, "../data/hamby224_test_explain.rds")
```

## Visualizing the LIME Explanations

Some plots to tryout working with the new explanations...

```{r}
hamby224_test_explain %>%
  ggplot(aes(x = feature_desc)) + 
  geom_bar() +
  coord_flip()
```

```{r}
hamby224_test_explain %>%
  filter(set == "1") %>%
  select(case, bullet1:land2, rfscore) %>%
  distinct() %>%
  ggplot(aes(x = land1, y = land2)) +
  geom_tile(aes(fill = rfscore)) +
  facet_grid(bullet1 ~ bullet2) +
  theme_bw() +
  scale_fill_gradient2(low = "grey", high = "orange", midpoint = 0.5)
```

```{r}
hamby224_test_explain %>%
  filter(set == "1") %>%
  select(case, bullet1:land2, samesource) %>%
  distinct() %>%
  ggplot(aes(x = land1, y = land2)) +
  geom_tile(aes(fill = samesource)) +
  facet_grid(bullet1 ~ bullet2) +
  theme_bw()
```

```{r, fig.width = 8, fig.height = 4}
lime::plot_explanations(hamby224_explain)
```

```{r}
hamby224_test_explain %>%
  filter(set == "1") %>%
  ggplot(aes(x = case, y = feature_desc)) + 
  geom_tile(aes(fill = feature_weight)) + 
  facet_grid(feature ~ label, space = "free", scale = "free") + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_fill_gradient2(midpoint = 0) +
  theme(legend.position = "bottom") +
  ylab("Feature Sets") 
```  

```{r}
hamby224_test_explain %>%
  filter(set == "1", samesource == "FALSE") %>%
  ggplot(aes(x = case, y = feature_desc)) + 
  geom_tile(aes(fill = feature_weight)) + 
  facet_grid(feature ~ bullet1, space = "free", scale = "free") + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_fill_gradient2(midpoint = 0)
```

```{r}
hamby224_test_explain %>%
  filter(set == "1", samesource == "FALSE") %>%
  ggplot(aes(x = case, y = feature_desc)) + 
  geom_tile(aes(fill = feature_weight)) + 
  facet_grid(bullet1 ~ bullet2, space = "free", scale = "free") + 
  theme(axis.text.x = element_text(angle = 90)) +
  scale_fill_gradient2(midpoint = 0) +
  theme(legend.position = "bottom")
```

# Results

# Discussion

# References

