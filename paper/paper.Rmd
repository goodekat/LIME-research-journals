---
title: "Interpreting Random Forest Predictions for Firearm Identification Using LIME"
author: "Katherine Goode and Heike Hofmann"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  pdf_document:
    number_sections: true
bibliography: references.bib
---

```{r setup, include = FALSE}
# Set knitr options
knitr::opts_chunk$set(echo = FALSE, eval = TRUE)

# Load libraries
library(tidyverse)
library(bulletr)
library(lime)
library(randomForest)
```

# Introduction

(need to finish adding sources)

The discipline of firearm identification examines bullets to determine the likelihood that a bullet found in a criminal case was fired from a particular gun. To do this, the bullet from the crime will be compared with a bullet that was known to be fired from the gun under evaluation. Traditionally, this is a procedure that has been performed by hand. Specially trained examiners visually compare the microscopic bullet striations that were created when the bullets passed through the gun barrel. Often a comparison microscope is used that allows the examiners to view both bullets at the same time (National Research Council 2009). The examiners use this ability to determine whether the two bullets were fired from the same gun barrel.

Recently, the scientific community has been encouraging the inclusion of more data driven techniques to be used in forensic investigations. These methods would allow for the reporting of a measure of uncertainty in addition to the conclusion drawn from the analysis. This led Hare, Hofmann, and Carriquiry (2017) to propose a new computer automated method of bullet matching that could supplement the visual inspection by the firearm examiners. Their method involves obtaining bullet signatures of the striations from the scans of the two bullets, computing variables that measure the similarity of the two signatures, and using a trained random forest model to determine the probability of a match based on the similarity variables. They trained their model on a set of known bullet matches and non-matches from the Hamby study. They demonstrated how the random forest model can be used to make prediction on a new set of bullet signature comparisons. The results from the paper suggest that the random forest model leads to highly accurate bullet matching predictions. The authors found that when their model was applied to a testing dataset (?), the resulting error rate was 0%.

While random forest models often result in good predictions as seen in Hare, Hofmann, and Carriquiry, it is well known that a disadvantage of random forest models and other machine learning techniques is that it is difficult to interpret the models (reference?). For example, it is not possible to tell which variables played an important role in the creation of individual predictions. This issue led to the development of LIME (reference), which is an algorithm that examines the behavior of the complicated model on a local scale around a new prediction using a linear regression model. This allows for the ability to understand which were the driving variables that led to a prediction of interest.

Since firearm identification identification is commonly used as evidence for convictions in court cases, it is important to be able to understand and assess the model that is being used to quantify the probability that a bullet was fired from a gun. LIME provides the ability to understand which were the key variables used by the random forest model to make a prediction, which would allow firearm examiners to check whether or not the predictions created by the random forest are based on reasonable variables. 

This paper provides an example of the application of LIME to a bullet matching problem. (provide more details about what is contained in the papers - i.e. section 2 describes the Hamby data; section 3 describes the random forest model and LIME; ...)

# Data

## Training Data: The Hamby...

(fill in once we know which data will be used to train the new random forest model)

```{r}
# Load in the training data (Hamby Data 173 and 252)
hamby173and252_train <- read.csv("../data/hamby173and252_train.csv")
```

## Testing Data: The Hamby 224 Clone

The Hamby 224 Clone is organized as a test set of a cloned (sub-)set of the Hamby 224 bullets. As with all Hamby sets [@hamby], Hamby set 224, is a collection of 35 bullets, organized as 20 known bullets and 15 questioned bullets. The known bullets are fired in pairs of two through one of ten consecutively manufactures P-85 barrels.
Clone set 224 is arranged as a test set of fifteen tests, one for each questioned bullet. Each test set is arranged as a combination of three bullets: two known bullets and a questioned bullet. The test asks for a decision on whether the questioned bullet comes from the same source as the two known bullets  or from a different source. This situation is similar to what a Firearms and Toolmarks Examiner might encounter in case work. 

```{r}
# Load in the Hamby 224 datasets
hamby224_set1 <- readRDS("../data/h224-set1-features.rds")
hamby224_set11 <- readRDS("../data/h224-set11-features.rds")
```

```{r}
# Obtain features used when fitting the rtrees random forest
rf_features <- rownames(rtrees$importance)

# If the test data does not exist, clean the data, create the test data, and save it
# Otherwise, load in the test data
if(!file.exists("../data/hamby224_test.csv")) {
  
  # Clean the Hamby 224 set 1 data
  hamby224_set1_cleaned <- hamby224_set1 %>%
    select(-bullet_score, -land1, -land2, -aligned, -striae, -features) %>%
    rename(bullet1 = bulletA,
           bullet2 = bulletB, 
           land1 = landA,
           land2 = landB) %>%
    mutate(study = factor("Hamby 224"), 
           set = factor("Set 1"),
           bullet1 = recode(factor(bullet1), "1" = "Known 1", "2" = "Known 2", "Q" = "Questioned"),
           bullet2 = recode(factor(bullet2), "1" = "Known 1", "2" = "Known 2", "Q" = "Questioned"),
           land1 = recode(factor(land1), "1" = "Land 1", "2" = "Land 2", "3" = "Land 3", 
                          "4" = "Land 4", "5" = "Land 5", "6" = "Land 6"),
           land2 = recode(factor(land2), "1" = "Land 1", "2" = "Land 2", "3" = "Land 3", 
                          "4" = "Land 4", "5" = "Land 5", "6" = "Land 6")) %>%
    select(study, set, bullet1:land2, rf_features, rfscore, samesource)

  # Clean the Hamby 224 set 11 data
  hamby224_set11_cleaned <- hamby224_set11 %>%
    select(-bullet_score, -land1, -land2, -aligned, -striae, -features) %>%
    rename(bullet1 = bulletA,
           bullet2 = bulletB, 
           land1 = landA,
           land2 = landB) %>%
    mutate(study = factor("Hamby 224"), 
           set = factor("Set 11"),
           bullet1 = recode(factor(bullet1), "Bullet 1" = "Known 1", "Bullet 2" = "Known 2", 
                            "Bullet I" = "Questioned"),
           bullet2 = recode(factor(bullet2), "Bullet 1" = "Known 1", "Bullet 2" = "Known 2", 
                            "Bullet I" = "Questioned")) %>%
    select(study, set, bullet1:land2, rf_features, rfscore, samesource)

  # Create a dataset with all combinations of lands and bullets comparisons for each set
  combinations <- data.frame(set = factor(rep(c("Set 1", "Set 11"), each = 324)),
                      expand.grid(land1 = factor(c("Land 1", "Land 2", "Land 3", 
                                                   "Land 4", "Land 5", "Land 6")),
                                  land2 = factor(c("Land 1", "Land 2", "Land 3", 
                                                   "Land 4", "Land 5", "Land 6")),
                                  bullet1 = factor(c("Known 1", "Known 2", "Questioned")),
                                  bullet2 = factor(c("Known 1", "Known 2", "Questioned"))))
  
  # Join the two cleaned Hamby 224 sets into one testing set
  hamby224_test <- suppressWarnings(bind_rows(hamby224_set1_cleaned,
                                              hamby224_set11_cleaned)) %>%
    mutate(set = factor(set),
           bullet1 = factor(bullet1),
           bullet2 = factor(bullet2),
           land1 = factor(land1),
           land2 = factor(land2)) %>%
    right_join(combinations, by = c("set", "land1", "land2", "bullet1", "bullet2")) %>%
    filter(!(bullet1 == "Questioned" & bullet2 == "Known 1"),
           !(bullet1 == "Questioned" & bullet2 == "Known 2"),
           !(bullet1 == "Known 2" & bullet2 == "Known 1")) %>%
    arrange(rfscore) %>%
    mutate(case = factor(1:length(study))) %>%
    select(case, study:samesource)
    
    
  # Save the test data as a .csv file
  write.csv(hamby224_test, "../data/hamby224_test.csv", row.names = FALSE)

} else {
 
  # Read in the test data
  hamby224_test <- read.csv("../data/hamby224_test.csv")
  
}
```

#  Methods

## Random Forest Model

## Overview of LIME

Step 0: Split iris data into training and testing datasets
Step 1: Fit a complex model to the training data
Step 2: Obtain distributions of the variables from the training data
Step 3: Sample from each of the variable distributions $n$ times
Step 4: Obtain predictions for sampled values using the complex model
For each testing case use the random forest model to make a prediction for each of the $n=5000$ samples
In the iris data, the predictions are represented by the probability that a flower is a particular species
Step 5: Obtain similarity score between data observation and sampled values
LIME uses exponential kernel function
  ...
where
$x_{obs}$: observed data vector to predict
$x_{sampled}$: sampled data vector from distribution of training variables
$D(\cdot, \cdot)$: distance function such as euclidean distance, cosine distance, etc.
$\sigma$: width (default set to 0.75 in lime)
Step 6: Perform feature selection by fiting a model to the sampled data and associated predictions (weighted by the similarity scores)
The user can specify the number of variables (features) they would like to select: $m$
With the iris data, the following three models will be fit to perform variable selection to select $m=2$ features:
To perform variable selection lime supports: 
 forward selection with ridge regression
 highest weight with ridge regression
 LASSO
 tree models
auto: forward selection if $m\le6$, highest weight otherwise
Step 7: Fit a simple model to regress the predictions on the $m$ selected predictor variables (weighted by the similarity scores)
Currently, `lime` is programmed to use ridge regression as the simple model
If the response is categorical, the user can select how many categories they want to explain
In this example, only setosa will be explained
If petal length and sepal length were selected as the most important features for the first case in the testing data, then the simple model is
Step 8: Extract the feature weights and use them as the explanations

## Applying LIME

```{r echo = FALSE}
# Apply the lime function if the file does not already exist
if(!file.exists("../data/hamby224_lime.rds")) {
  
  # Apply the lime function from the lime package (with a seed set)
  # Note that the as_classifier must be added since rtrees is from the
  # randomForest package and not fit using caret or one of the other 
  # available models specified in the lime package. Additionally, the
  # randomForest package must be loaded in order to run the functions
  # from the lime package. (I should check on exactly how this works.)
  set.seed(84902)
  hamby224_lime <- lime(x = hamby173and252_train %>% select(rf_features),
                        model = as_classifier(rtrees))
  
  # Save the lime object
  saveRDS(hamby224_lime, "../data/hamby224_lime.rds")

} else {
  
  # Load in the lime object
  hamby224_lime <- readRDS("../data/hamby224_lime.rds")
  
}
```

```{r}
# Apply explain function if the file does not already exist
if(!file.exists("../data/hamby224_explain.rds")) {
  
  # Apply the explain function from the lime package (with a seed set)
  set.seed(84902)
  hamby224_explain <- lime::explain(hamby224_test %>% 
                                      arrange(case) %>% 
                                      select(rf_features) %>% 
                                      na.omit(), 
                                    hamby224_lime,
                                    labels = "FALSE",
                                    n_features = 3)
  
  # Save the explainer object
  saveRDS(hamby224_explain, "../data/hamby224_explain.rds")
  
} else {
  
  # Load in the explain object
  hamby224_explain <- readRDS("../data/hamby224_explain.rds")
  
}
```

```{r echo = FALSE}
# Function to use for creating bin labels in the test_explain dataset
bin_labeller <- function(feature, feature_value){

  if (is.na(feature)) {
    
    # Set feature_bin to NA if feature is NA
    feature_bin <- NA
    
  } else {
    
    # Create a dataframe of bins cuts
    bin_cuts <- data.frame(matrix(unlist(hamby224_lime$bin_cuts), nrow = 9, byrow = TRUE)) %>%
      rename("Q0" = X1, "Q25" = X2, "Q50" = X3, "Q75" = X4, "Q100" = X5) %>%
      mutate(Feature = rf_features) %>%
      select(Feature, Q0:Q100)
    
    # Subset the bin cuts table to the selected feature
    feature_bin_cuts <- bin_cuts %>% filter(Feature == feature)
  
    # Determine which bin the case falls in
    if(feature_value <= feature_bin_cuts$Q25){
      feature_bin <- paste(feature, "(lower bin)")
    } else if (feature_bin_cuts$Q25 < feature_value & feature_value <= feature_bin_cuts$Q50){
      feature_bin <- paste(feature, "(lower middle bin)")
    } else if (feature_bin_cuts$Q50 < feature_value & feature_value <= feature_bin_cuts$Q75){
      feature_bin <- paste(feature, "(upper middle bin)")
    } else if (feature_bin_cuts$Q75 < feature_value){
      feature_bin <- paste(feature, "(upper bin)")
    }
       
  }

  # Return the bin
  return(feature_bin)

}
```

```{r}
# Create the test_explain combined data if the file does not already exist
if(!file.exists("../data/hamby224_test_explain.rds")) {
  
  # Join the data and the explanations and edit and add additional variables
  hamby224_test_explain <- hamby224_test %>%
    mutate(case = as.character(case)) %>%
    full_join(hamby224_explain, by = "case") %>%
    mutate(case = factor(case),
           feature_desc = factor(feature_desc),
           feature = factor(feature),
           feature_bin = mapply(bin_labeller, feature = feature, feature_value = feature_value)) %>%
    mutate(feature_number = readr::parse_number(feature_desc),
           strictly_less = FALSE)
  
  # Finish creating the strictly less than variable
  hamby224_test_explain$strictly_less[grep("< ", hamby224_test_explain$feature_desc)] <- TRUE
  
  # Reorder the variables of feature_desc and feature_bin for plotting purposes
  hamby224_test_explain <- hamby224_test_explain %>%
    mutate(feature_desc = reorder(feature_desc, strictly_less),
           feature_desc = reorder(feature_desc, feature_number),
           feature_desc = reorder(feature_desc, as.numeric(feature))) %>%
    select(case:feature_desc, feature_number:feature_bin, data, prediction)

  # Save the combined test and explain data
  saveRDS(hamby224_test_explain, "../data/hamby224_test_explain.rds")
   
} else {
  
  # Load in the data
  hamby224_test_explain <- readRDS("../data/hamby224_test_explain.rds")
  
}
```

## Visualizing the LIME Explanations

Thoughts on the visualizations: 

- It would be interesting to see the "magnitude" associated with a variable for a prediction, but
  this would require obtaining the scaled values of the perturbations.
- This seems much more meaningful to me than just the model coefficient associated with the variable.
- The current version shows which variables in the model have the largest coefficients.
- However, the importance of the variable might change depending on the observed value associated
  with the prediction of interest.

```{r}
hamby224_test_explain %>%
  ggplot(aes(x = feature_desc)) + 
  geom_bar() +
  coord_flip()
```

```{r}
hamby224_test_explain %>%
      filter(set == "Set 1") %>%
      mutate(rfscore = round(rfscore, 3)) %>%
      select(case, bullet1, bullet2, land1, land2, rfscore) %>%
      distinct() %>%
      ggplot(aes(x = land1, y = land2, label = bullet1, label2 = bullet2,
                 text = paste('Bullets Compared: ', bullet1, "-", land1, 
                              "vs", bullet2, "-", land2,
                              '\nRandom Forest Score: ', 
                              ifelse(is.na(rfscore), "Missing due to tank rash", rfscore)))) +
      geom_tile(aes(fill = rfscore)) +
      facet_grid(bullet2 ~ bullet1, scales = "free") +
      theme_minimal() +
      scale_fill_gradient2(low = "darkgrey", high = "darkorange", midpoint = 0.5) +
      theme(axis.text.x = element_text(angle = 45, hjust = 1),
            strip.text.x = element_blank(),
            strip.text.y = element_blank()) +
      labs(x = "Known 1                            Known 2                            Questioned", 
           y = "Known 1                            Known 2                            Questioned", 
           fill = "RF Score")
```

# Results

# Discussion

# References

