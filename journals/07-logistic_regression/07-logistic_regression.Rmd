---
title: "07-logistic_regression"
author: "Katherine Goode"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE, 
                      cache = TRUE)
```

# Overview

I have been thinking a lot about it is difficult to determine whether LIME is providing reasonable explanations, because we cannot know what the random forest is doing. That is the point of LIME. Heike suggested that we fit a logistic regression model to the training bullet data. We can then apply LIME to the logistic regression and determine if the explanations match what we would expect based on the coefficients of the logistic regression that we can interpret. She also suggested including interactions in the logistic regression model. This journal goes through the process of fitting several logisitic regression models, applying LIME to them, and comparing the results.

```{r}
# Load libraries
library(lime)
library(tidyverse)
```

# The Data

The cleaned training and testing datasets are loaded in below.

```{r}
# Load in the training data (Hamby Data 173 and 252)
hamby173and252_train <- read.csv("../../data/hamby173and252_train.csv")

# Load in the testing data (Hamby Data 224 Sets 1 and 11)
hamby224_test <- read.csv("../../data/hamby224_test.csv")
```

A vector containing the features used in the random forest `rtrees` is created below that will be used when creating some of the plots in this journal.

```{r}
# Obtain features used when fitting the rtrees random forest
rf_features <- rownames(bulletr::rtrees$importance)
```

# Logistic Regression Models

### Main Effects Only

The code below fits a logistic regression model to the training data using the `train` function from the caret package. The nine features used to fit `rtrees` are included as main effects only. The features are standardized prior to fitting the model using the `preProcess = "scale"` in `train`.

```{r}
# Fit or load the logistic regression model with only main effects
if(!file.exists("./data/logistic_mains.rds")) {
  
  # Set a seed
  set.seed(20190226)
  
  # Fit the model
  logistic_mains <- caret::train(as.factor(samesource) ~ ccf + rough_cor + D + sd_D + 
                                   matches + mismatches + cms + non_cms + sum_peaks,
                                 preProcess = "scale",
                                 data = hamby173and252_train, 
                                 method = "glm", 
                                 family = "binomial")

  # Save the model
  saveRDS(logistic_mains, "./data/logistic_mains.rds")

} else{
  
  # Load the model
  logistic_mains <- readRDS("./data/logistic_mains.rds")
  
}

summary(logistic_mains)
```

The output from the model is shown below. The features of ccf and matches stand out as the most important features in the model.

```{r}
# Summary of the model
summary(logistic_mains)
```

### All Two Way Interactions

The code below fits a logistic regression model to the training data using the `train` function from the caret package. The nine features used to fit `rtrees` are included as main effects and with all two way interactions. The features are standardized prior to fitting the model using the `preProcess = "scale"` in `train`.

```{r}
# Fit or load the logistic regression model with all two way interactions
if(!file.exists("./data/logistic_inters2.rds")) {
  
  # Set a seed
  set.seed(20190226)
  
  # Fit the model
  logistic_inters2 <- caret::train(as.factor(samesource) ~
                                       (ccf + rough_cor + D + sd_D + matches + 
                                          mismatches + cms + non_cms + sum_peaks)^2,
                                     preProcess = "scale",
                                     data = hamby173and252_train,
                                     method = "glm", 
                                     family = "binomial")
  
  # Save the model
  saveRDS(logistic_inters2, "./data/logistic_inters2.rds")

} else{
  
   # Load the model
  logistic_inters2 <- readRDS("./data/logistic_inters2.rds")
  
}
```

The output from this model is not shown.

```{r eval = FALSE}
# Summary of the model
summary(logistic_inters2)
```

### Comparing the Two Models

The results as computed by caret on the training data are shown below for the two logistic regression models. The accuracy shows that the models with two way interactions performs better on the training data.

```{r}
# Results from the models
data.frame(model = c("mains", "inters2")) %>%
  bind_cols(bind_rows(logistic_mains$results, logistic_inters2$results))
```

The AICs from the models are shown below. The model with two way interactions performs the best based on AIC.

```{r}
AIC(logistic_mains$finalModel)
AIC(logistic_inters2$finalModel)
```

I also wanted to know how the models perform on the test data. The models are used to make predictions on the test data and the MSEs are computed for each model. These are shown in the table below. The model with main effects only has the smallest MSE. I am guessing that the other model is overfitting the data.

```{r}
data.frame(obs = hamby224_test %>% 
             pull(samesource) %>% na.omit(),
           mains = predict(logistic_mains, hamby224_test %>% select(rf_features)),
           inters2 = predict(logistic_inters2, hamby224_test %>% select(rf_features))) %>%
  mutate(mains_sqerrs = (obs - as.logical(mains))^2,
         inters2_sqerrs = (obs - as.logical(inters2))^2) %>%
  summarise_at(vars(mains_sqerrs, inters2_sqerrs), 
               function(x) sum(x) / length(x)) %>%
  rename(mains_mse = mains_sqerrs, inters2_mse = inters2_sqerrs)
```

# Applying LIME to the Models

### Default LIME Applied to Main Effects Model

The functions `lime` and `explain` from the lime package are applied below to the logisitc regression model with only main effects.

```{r}
# Create or load the lime and explain objects for the main effects logisitic regression model
if(!file.exists("./data/lime_explain_mains.rds")) {
  
  # Set a seed
  set.seed(20190226)
  
  # Apply lime
  lime_mains <- lime(x = hamby173and252_train %>% select(rf_features), 
                     model = logistic_mains)
  
  # Apply explain
  explain_mains <- explain(x = hamby224_test %>%
                             select(rf_features) %>% 
                             na.omit(), 
                           explainer = lime_mains, 
                           n_labels = 1,
                           n_features = 3)
  
  # Join the lime and explain objects in a list
  lime_explain_mains <- list(lime = lime_mains, explain = explain_mains)
  
  # Save the lime and explain objects
  saveRDS(lime_explain_mains, "./data/lime_explain_mains.rds")

} else {
  
  # Load the lime and explain objects
  lime_explain_mains <- readRDS("./data/lime_explain_mains.rds")
  
}
```

```{r}
plot_features(lime_explain_mains$explain[1:12,])
```

```{r}
coefs <- logistic_mains$finalModel$coefficients %>% round(2)
```

The logistic regression model is 

$\log\left(\frac{\hat{p}}{1-\hat{p}}\right)=$ `r coefs[[1]]` + `r coefs[[2]]` ccf + `r coefs[[3]]` rough_cor + `r coefs[[4]]` D + `r coefs[[5]]` sd_D + `r coefs[[6]]` matches + `r coefs[[7]]` mismatches + `r coefs[[8]]` cms + `r coefs[[9]]` non_cms + `r coefs[[10]]` sum_peaks

where $\hat{p}=P(\mbox{samesource = TRUE})$.

I started trying to compare the results from LIME to the logistic regression model, but I realized that I need to standardize my test data before I use the model to make predictions.

```{r}
m = function(x) coefs[2:10] * x
m(hamby224_test[1,] %>% select(rf_features))
hamby224_test[1:4,] %>% select(rf_features)
coefs
hamby224_test[1:4,] %>% select(rf_features) * coefs[2:10]
```


```{r}
mains_test_explain <- hamby224_test %>%
  mutate(case = as.character(case)) %>%
  full_join(lime_explain_mains$explain, by = "case") %>%
  mutate(case = factor(case),
         feature = factor(feature))
```

Below is a plot of the three chosen features for each of the cases faceted by set. The features are ordered by order they were chosen by lime (ordered by magnitude of the coefficients).

```{r}
mains_test_explain %>%
  na.omit() %>%
  arrange(case, desc(abs(feature_weight))) %>%
  mutate(feature_order = rep(c("first", "second", "third"), n() / 3)) %>%
  select(case, set, feature, feature_order) %>%
  spread(feature_order, feature) %>%
  arrange(set, first, second, third) %>%
  mutate(order = 1:n()) %>%
  gather(feature_order, feature, 3:5) %>%
  ggplot(aes(x = feature_order, y = order, fill = feature)) + 
  geom_tile() + 
  facet_grid(set ~ ., scales = "free_y") +
  theme_bw() +
  gretchenalbrecht::scale_fill_gretchenalbrecht(palette = "last_rays", discrete = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) + 
  labs(x = "Order of Features Chosen", y = "Case", fill = "Feature")
```

```{r}
pca_results <- princomp(hamby224_test %>% select(rf_features) %>% na.omit())
pca_results$loadings
z1 <- pca_results$scores[,1]
z2 <- pca_results$scores[,2]
ggplot(data.frame(z1, z2), aes(x = z1, y = z2)) + 
  geom_point()
biplot(pca_results)
```

# Session Info

```{r}
sessionInfo()
```
