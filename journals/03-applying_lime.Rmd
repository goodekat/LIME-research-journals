---
title: "03-applying_lime"
author: "Katherine Goode"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```

# Overview

This journal contains a draft of the the lime procedure, the application of lime to the bullet data, and a plot created by Heike to visualize the lime explanations.

```{r}
# Load libraries
library(tidyverse)

# Source functions
source("../code/helper_functions.R")
```

# Data

The training and testing datasets are loaded in below.

```{r}
# Read in the Hamby 224 test data
hamby224_test <- read.csv("../data/hamby224_test.csv") 

# Read in the test_explain data
hamby224_test_explain <- readRDS("../data/hamby224_test_explain.rds")
```

A vector containing the features used in the random forest `rtrees` is created below.

```{r}
# Obtain features used when fitting the rtrees random forest
rf_features <- rownames(bulletr::rtrees$importance)
```

# Draft of LIME Procedure

### Less Detailed Version

I wrote this up to start thinking about how to describe the procedure that the `lime` R package uses to implement the LIME algorithm. It needs a lot of work, but it is a start. The final version of this will end up in the technical stats paper critiquing LIME. The version in the firearm examiner's paper will be much simpler...

The steps below explain the procedure that the R package is using to apply the LIME algorithm to the bullet matching predictions on the Hamby 224 clone dataset made by the random forest model from Hare. For simplicity, the steps are described as what happens to one case in the test data. Thus, the steps (2) through (7) are repeated for each observation in the testing dataset.

Let
  $$Y_{jk} = \begin{cases} 
  1 & \mbox{ if bullets } j \mbox{ and } k \mbox{ were fired from the same gun barrel }\\
  0 & \mbox{otherwise}
  \end{cases}$$
be the response variable in the training dataset, and $X_1,...,X_9$ correspond to the nine features in the training dataset. Let $X'_1,...,X'_9$ be the 

1. Distributions for each of the features in the training data are obtained. 
    + The method that `lime` uses to obtain the distribution differs based on the feature type. All of the features in the Hamby datasets are numeric. For numeric features, the default option in `lime` (`quantile_bins = TRUE`) computes the quantiles of each feature based on the number of bins selected. The default number of bins is 4 (`n_bins = 4`).

2. Many ($n$) samples from each of the feature distributions are drawn.
     + To do this, `lime` has several options (mostly quoted from `lime` package for now):
      * bin\_continuous = TRUE should continuous variables be binned?
      * quantile\_bins = TRUE should the ins for n\_bins be based on quantiles or spread evenly
      * n\_bins = 4 number of bins if bin\_continuous is TRUE
      * use\_density = TRUE if bin\_continuous is FALSE, should continuous data be sampled using kernel density estimation (if not, then will assume normal for continuous variable)

3. Predictions for the testing data using the random forest model are computed.
     + The random forest model `rtrees` is used to make a prediction for the observation from the test dataset and each of the $n=5000$ samples as to whether or not the comparison of the two bullets in the test case are a match. Since the random forest is a classification model, `lime` is set to return the prediction probabilities.

4. Similarity score between the observation in the testing data and each of the $n=5000$ sampled values are obtained.
    + The way that the similarity score is computed depends on the type of feature. Since all of the features in the Hamby 224 test dataset are continuous, the simulated values are first converted into 0-1 features where a 1 indicates that the feature from the simulated value falls in the same bin as the observed data point and a 0 indicates that the feature is not in the same bin as the observed data point. Then, by default, the Gower distance is used to compute the similarity score. (using the `gower` package in R)

5. Feature selection is performed by fitting some type of regression model weighted by the similarity scores is to the simulated data and the observed value. The 0-1 versions of the features are used.
    + The user can specify the number of features, $m$, they would like to select to explain the prediction. `lime` supports the following options for feature selection
      * forward selection with ridge regression
      * highest weight with ridge regression
      * LASSO model
      * tree model
      * default: forward selection if $m\le6$ with a ridge regression model, highest weight with ridge regression otherwise

6. A ridge regression model is fit as the simple model by regressing the prediction probabilities on the $m$ selected predictor variables and weighted by the similarity scores. If the response is categorical, the user can select how many categories and which categories they want to explain.
  $$P(Match = TRUE) = \beta_0 + 
  \beta_1 \cdot I\left[X_1 \in \mbox{obs bin}\right] + 
  \beta_2 \cdot I\left[X_2 \in \mbox{obs bin}\right] + 
  \beta_3 \cdot I\left[X_3 \in \mbox{obs bin}\right]$$
For the prediction of interest, 
  $$P(Match = TRUE) = \beta_0 + \beta_1 + \beta_2 + \beta_3.$$
7. The feature weights are extracted and used as the explanations.

Note: I realized that if `bin_continuous = FALSE`, then bins are not used at all. Instead, a kernel density estimator is used to sample from the distribution (or a normal distribution if specified), and then the ridge regression models are fit without "numerified" values.

### More Detailed Version

I need to install math jax to get this to work...

##### Notation

\begin{itemize}
\item $x\in\mathbb{R}^d$: original representation of an instance being explained
\begin{itemize}
\item e.g. feature vector containing word embeddings
\end{itemize}
\item $x'\in\mathbb{R}^{d'}$: vector for the interpretable representation of the instance being explained
\begin{itemize}
\item e.g. bag of words
\end{itemize}
\item $G$: class of potentially interpretable models
\begin{itemize}
\item e.g. linear models, decision trees, rule lists
\end{itemize}
\item $g$: explanation model where $g:\mathbb{R}^{d'}\rightarrow\mathbb{R}$ and $g\in G$
\item $\Omega(g)$: measure of complexity of $g$
\begin{itemize}
\item e.g. depth of a tree, number of non-zeros in a linear model
\end{itemize}
\item $f$: model that is being explained where $f:\mathbb{R}^d\rightarrow\mathbb{R}$
\begin{itemize}
\item note: in classification $f(x)$ is the probability that $x$ belongs to a certain class
\end{itemize}
\item $\Pi_x(z)$: proximity measure between an instance $z$ to $x$ which defines a locality around $x$
\item $\mathcal{L}(f, g, \Pi_x)$: a measure of how unfaithful $g$ is in approximating $f$ in the locality defined by $\Pi_x$
\end{itemize}

##### Step by Step Procedure

Step 1: 

# Application of LIME

```{r}
# Apply the run_lime function if the lime results file does not already exist
if(!file.exists("../data/hamby224_lime_inputs.rds")) {
  
  # Specify the input options to use with lime
  hamby224_lime_inputs <- list(bin_continuous = c(rep(TRUE, 20), 
                                                  rep(FALSE, 2)),
                               quantile_bins = c(rep(TRUE, 5), 
                                                 rep(FALSE, 5), 
                                                 rep(TRUE, 12)),
                               nbins = c(rep(2:6, 4), 
                                         rep(4, 2)),
                               use_density = c(rep(TRUE, 20), TRUE, FALSE),
                               bin_method = c(rep("quantile_bins", 5),
                                              rep("equally_spaced", 5),
                                              rep("tree", 10),
                                              rep("quantile_bins", 2)),
                               response = c(rep(NA, 10), 
                                            rep("samesource", 5), 
                                            rep("rfscore", 5), 
                                            rep(NA, 2)))
  
  # Tell R to run the upcoming code in parallel
  plan(multiprocess)
  
  # Apply lime to the full training data with the specified input options
  hamby224_lime_explain <- future_pmap(.l = hamby224_lime_inputs,
             .f = run_lime, # run_lime is one of my helper functions
             features = rf_features,
             train = hamby173and252_train,
             test = hamby224_test %>% 
               arrange(case) %>% 
               select(rf_features) %>% 
               na.omit(),
             rfmodel = as_classifier(rtrees),
             label = "TRUE",
             nfeatures = 3,
             seed = TRUE)
  
  # Separate the lime and explain function results from the full data
  hamby224_lime <- map(hamby224_lime_explain, function(list) list$lime)
  hamby224_explain <- map_df(hamby224_lime_explain, function(list) list$explain)
  
  # Name the items in the lime list
  names(hamby224_lime) <- map_chr(1:22, function(case) 
      sprintf("case: bin_continuous = %s, quantile_bins = %s, nbins = %0.f, use_density = %s, bin_method = %s, response = %s",
              hamby224_lime_inputs$bin_continuous[case],
              hamby224_lime_inputs$quantile_bins[case],
              hamby224_lime_inputs$nbins[case],
              hamby224_lime_inputs$use_density[case],
              hamby224_lime_inputs$bin_method[case],
              hamby224_lime_inputs$response[case]))

  # Turn the lime input options into a dataframe before saving it
  hamby224_lime_inputs <- hamby224_lime_inputs %>%
    unlist() %>%
    matrix(ncol = length(hamby224_lime_inputs), 
           dimnames = list(NULL, names(hamby224_lime_inputs))) %>%
    as.data.frame() %>%
    mutate(case = 1:length(hamby224_lime_inputs$quantile_bins)) %>%
    select(case, bin_continuous:response)
  
  # Save the lime objects
  saveRDS(hamby224_lime_inputs, "../data/hamby224_lime_inputs.rds")
  saveRDS(hamby224_lime, "../data/hamby224_lime.rds")
  saveRDS(hamby224_explain, "../data/hamby224_explain.rds")
  
} else {
  
  # Load in the lime objects
  hamby224_lime_inputs <- readRDS("../data/hamby224_lime_inputs.rds")
  hamby224_lime <- readRDS("../data/hamby224_lime.rds")
  hamby224_explain <- readRDS("../data/hamby224_explain.rds")
  
}
```

```{r}
# Create a dataframe with the bins
if (!file.exists("../data/hamby224_bins.csv")) {
  
  # Create a list a dataframes with the bin boundaries and bins 
  # for the different evaluations of the lime functions
  hamby224_bin_list <- map(hamby224_lime, create_bin_data)
  
  # Save the bin boundaries and the bins as separate dataframes
  hamby224_bin_boundaries <- map(hamby224_bin_list, function(m) m$boundaries)
  hamby224_bins <- map(hamby224_bin_list, function(m) m$bins)
  
  # Save the bin boundaries and bins
  saveRDS(hamby224_bin_boundaries, "../data/hamby224_bin_boundaries.rds")
  saveRDS(hamby224_bins, "../data/hamby224_bins.rds")
  
} else {
  
  # Load in the bin boundaries and bins
  hamby224_bin_boundaries <- readRDS("../data/hamby224_bin_boundaries.rds")
  hamby224_bins <- readRDS("../data/hamby224_bins.rds")
  
}
```

```{r}
# Create the test_explain combined data if the file does not already exist
if(!file.exists("../data/hamby224_test_explain.rds")) {
  
  # Join the data and the explanations and edit and add additional variables
  # Create the feature bin labels using my function "bin_labeller"
  hamby224_test_explain <- hamby224_test %>%
    mutate(case = as.character(case)) %>%
    full_join(hamby224_explain, by = "case") %>%
    mutate(case = factor(case),
           feature_desc = factor(feature_desc),
           feature_bin = pmap_chr(list(feature = feature, 
                                  feature_value = feature_value,
                                  b_c = bin_continuous,
                                  q_b = quantile_bins,
                                  n_b = nbins,
                                  u_d = use_density,
                                  b_m = bin_method,
                                  r_v = response),
                            .f = bin_labeller, # bin_labeller is one of my helper functions
                            bin_data = hamby224_bin_boundaries,
                            case_info = hamby224_lime_inputs)) %>%
    mutate(feature = factor(feature),
           nbins = factor(nbins),
           feature_number = readr::parse_number(feature_desc),
           strictly_less = FALSE) %>%
    arrange(nbins)
  
  # Finish creating the strictly less than variable
  hamby224_test_explain$strictly_less[grep("< ", hamby224_test_explain$feature_desc)] <- TRUE
  
  # Reorder the variables of feature_desc and feature_bin for plotting purposes and
  # create new variables of situation and bin_situation
  hamby224_test_explain <- hamby224_test_explain %>%
    mutate(feature_desc = reorder(feature_desc, strictly_less),
           feature_desc = reorder(feature_desc, feature_number),
           feature_desc = reorder(feature_desc, as.numeric(feature))) %>%
    mutate(nbins = as.numeric(as.character(nbins)),
           situation = ifelse(bin_continuous == TRUE & bin_method == "quantile_bins", 
                              sprintf("%.0f quantile", nbins),
                              ifelse(bin_continuous == TRUE & bin_method == "equally_spaced",
                                     sprintf("%.0f equally spaced", nbins),
                                     ifelse(bin_continuous == TRUE & bin_method == "tree" &
                                              response == "samesource",
                                            sprintf("%.0f samesource tree", nbins),
                                            ifelse(bin_continuous == TRUE & bin_method == "tree" &
                                              response == "rfscore",
                                              sprintf("%.0f rfscore tree", nbins),
                                              ifelse(bin_continuous == FALSE & 
                                                     use_density == TRUE, 
                                                     "kernel density", 
                                                     "normal approximation"))))) %>%
             fct_relevel("2 quantile", "3 quantile", "4 quantile",
                         "5 quantile", "6 quantile", "2 equally spaced",
                         "3 equally spaced", "4 equally spaced",
                         "5 equally spaced", "6 equally spaced",
                         "2 samesource tree", "3 samesource tree",
                         "4 samesource tree", "5 samesource tree",
                         "6 samesource tree")) %>%
    mutate(bin_situation = ifelse(bin_method == "quantile_bins" & 
                                  bin_continuous == TRUE,
                                  "quantile",
                                  ifelse(bin_method == "equally_spaced" & 
                                         bin_continuous == TRUE,
                                         "equally spaced", 
                                         ifelse(bin_method == "tree" & 
                                                bin_continuous == TRUE & 
                                                response == "samesource",
                                                "samesource tree", 
                                                ifelse(bin_method == "tree" & 
                                                       bin_continuous == TRUE & 
                                                       response == "rfscore",
                                                       "rfscore tree", 
                                                       ifelse(bin_continuous == FALSE & 
                                                       use_density == TRUE, 
                                                       "kernel density", 
                                                       "normal approximation")))))) %>%
    mutate(bin_situation = factor(bin_situation)) %>%
    select(situation, bin_situation, bin_continuous:response, case:feature_desc,
           feature_bin:strictly_less, data, prediction)

  # Save the combined test and explain data
  saveRDS(hamby224_test_explain, "../data/hamby224_test_explain.rds")
   
} else {
  
  # Load in the data
  hamby224_test_explain <- readRDS("../data/hamby224_test_explain.rds")
  
}
```

```{r}
# Create the lime comparison data if the file does not already exist
if(!file.exists("../data/hamby224_lime_comparisons.rds")) {
  
  # Create a data frame with the interesting information relating to the different
  # evaluations of lime and compute the difference and mean between the rf and rr
  # model predictions
  hamby224_lime_comparisons <- hamby224_test_explain %>%
    select(-data, -prediction) %>%
    group_by(case, bin_continuous, quantile_bins, nbins, use_density, bin_method, response) %>%
    slice(1) %>%
    ungroup() %>%
    select(situation, bin_situation, bin_method, bin_continuous, quantile_bins, response, 
           nbins, use_density, set, case, rf_features, rfscore, model_prediction, model_r2) %>%
    mutate(diff = rfscore - model_prediction,
           mean = (rfscore + model_prediction) / 2)
    
  
  # Save the lime comparison data frame
  saveRDS(hamby224_lime_comparisons, "../data/hamby224_lime_comparisons.rds")
  
} else {
  
  # Load in the lime comparison data frame
  hamby224_lime_comparisons <- readRDS("../data/hamby224_lime_comparisons.rds")
  
}
```

# Plot of Bin Frequencies

Heike made a plot with the structure of the one below when we began with the default settings of `lime`. This one has been created from the lime explanations with 2 quantile bins. It includes all three of the chosen features for each case in the testing dataset. For both sets, the cutoff of 0.275 < ccf occurs the most frequently.

```{r fig.height = 10}
# Plot of fequency for each bin division for 2 quantile bins
hamby224_test_explain %>%
  filter(situation == "2 quantile") %>%
  ggplot(aes(x = feature_desc)) +
  geom_bar() +
  coord_flip() + 
  facet_grid(set ~ .)
```

# Session Info

```{r}
sessionInfo()
```

