---
title: "Identifying `rtrees` Training Data"
author: "Katherine Goode"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    theme: cerulean
    highlight: textmate
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  eval = TRUE,
  cache = FALSE, 
  dpi = 300
)
```

This journal contains work to identify the data used to train `rtrees` (contained in both `bulletr` and `bulletxtrctr`). We recently discovered some discrepancies between `rtrees` and the training data we were using (`hamby-comparisons.csv`, previously `features-hamby173and252.csv`). Unfortunately, the original work by Eric is not well documented, so it is difficult to know for sure which dataset was used to train the model. However, Eric recently pointed us to some [code](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R), which he believes was used to train `rtrees`. Heike was able to rerun part of the code to extract data from the CSAFE database that was created by the first part of the code (scans to features). The new data (`CCFs_withlands.csv`) contains the same number of rows the number of predictions associated with `rtrees`. I have gathered all of our work trying to determine that `CCFs_withlands` is the data (or very similar to the data) used to train `rtrees` in this journal.

```{r}
library(cowplot)
library(dplyr)
library(ggplot2)
library(purrr)
library(randomForest)
library(stringr)
library(tidyr)
```

# Raw Datasets

This section contains code for loading and performing initial comparisons of the raw datasets.

## Load Data

Load the data provided by Heike and CSAFE that we have been using and believed to be the training data for rtrees:

```{r}
hamby_comparisons_raw <- read.csv("../../../data/raw/hamby-comparisons.csv")
```

Load the data extracted (on 2020-09-23) from the CSAFE database and corresponds to the [R script](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R) Eric believes to be the one used to train `rtrees`.

```{r}
CCFs_withlands_raw <- read.csv("../../../data/raw/CCFs_withlands.csv")
```

Obtain the features used to train `rtrees` for use throughout this journal:

```{r}
rtrees_features <- rownames(bulletxtrctr::rtrees$importance)
```

## Initial Comparisons

Dimensions of the raw datasets:

```{r}
dim(hamby_comparisons_raw)
dim(CCFs_withlands_raw)
```

Note that `CCFs_withlands` has the same number of rows as the number of predictions associated with `rtrees`:

```{r}
length(bulletxtrctr::rtrees$predicted)
```

Comparing summaries of the distributions of the features used to train `rtrees` from the two datasets. Note that the main differences are seen with the distributions of `D` (distance) and `sd_D` (standard deviation of distance):

```{r}
summary(hamby_comparisons_raw %>% select(all_of(rtrees_features)))
summary(CCFs_withlands_raw %>% select(all_of(rtrees_features)))
```

This result is even true when the observations in `hamby_comparisons` known to have tank rash (`flag == FALSE`) are removed. This seems to suggest that the units of `D` and `sd_D` changed from `CCFs_withlands`:  

```{r}
summary(hamby_comparisons_raw %>% filter(flag == FALSE) %>% select(all_of(rtrees_features)))
```

Comparing visualizations of the distributions of the features used to train `rtrees` from the two datasets to again see the differences in distributions of `D` and `sd_D`:

```{r fig.width = 10, fig.height = 3}
bind_rows(
  hamby_comparisons_raw %>%
    filter(flag == FALSE) %>%
    select(all_of(rtrees_features)) %>%
    pivot_longer(cols = everything()) %>%
    mutate(dataset = "hamby_comparisons"),
  CCFs_withlands_raw %>% select(all_of(rtrees_features)) %>%
    pivot_longer(cols = everything()) %>%
    mutate(dataset = "CCFs_withlands")
) %>%
  ggplot(aes(x = value, fill = dataset)) + 
  geom_histogram() +
  facet_grid(dataset ~ name)
```

# Data Cleaning

There are discrepancies in the naming conventions of the two datasets. This section contains the code that identifies the differences and cleans the data.

## Extracting Variables of Interest

The following variables are contained in the raw versions of the data. Note that they have different variables and different names. For our analysis, we only need the variables identifying the lands, the features used to train `rtrees`, the ground truth for whether or not the bullets are a match, and variables flagging bullets with tank rash.

```{r}
names(hamby_comparisons_raw)
names(CCFs_withlands_raw)
```

The code below separates the land id variables in `hamby_comparisons_raw` into separate columns for study, barrel, bullet, and land and selects only the variables of interest. 

```{r}
hamby_comparisons_select <- 
  hamby_comparisons_raw %>%
  separate(land_id1, c("study1", "barrel1", "bullet1", "land1")) %>%
  separate(land_id2, c("study2", "barrel2", "bullet2", "land2")) %>%
  select(
    study1,
    barrel1,
    bullet1,
    land1,
    study2,
    barrel2,
    bullet2,
    land2,
    all_of(rtrees_features),
    same_source,
    flag
  )
```

The code below renames some of the variables in `CCFs_withlands_raw`, selects only the variables of interest, and converts all land labels to characters.

```{r}
CCFs_withlands_select <- 
  CCFs_withlands_raw %>%
  rename(
    "study1" = "study.x",
    "barrel1" = "barrel.x",
    "bullet1" = "bullet.x",
    "land1" = "land.x",
    "study2" = "study.y",
    "barrel2" = "barrel.y",
    "bullet2" = "bullet.y",
    "land2" = "land.y",
    "same_source"= "match"
  ) %>%
  select(
    study1,
    barrel1,
    bullet1,
    land1,
    study2,
    barrel2,
    bullet2,
    land2,
    all_of(rtrees_features),
    same_source
  ) %>%
  mutate(across(c(barrel1, bullet1, land1, barrel2, bullet2, land2), as.character))
```

Check to make sure the structures of the two datasets agree:

```{r}
hamby_comparisons_select %>% str()
CCFs_withlands_select %>% str()
```

## Matching Labels

The function below extracts the labels from the two datasets for a given variable name `var` and creates a plot to show the discrepancies between `hamby_comparison_select` and `CCFs_withlands_select`.

```{r}
plot_labels <- function(var, ccf_data) {
  
  # Extract the labels
  hc_labels <-
    unique(c(
      hamby_comparisons_select %>% pull(paste0(var, "1")),
      hamby_comparisons_select %>% pull(paste0(var, "2"))
    ))
  ccfwl_labels <-
    unique(c(
      ccf_data %>% pull(paste0(var, "1")),
      ccf_data %>% pull(paste0(var, "2"))
    ))

  # Plot the labels
  data.frame(data = c(
    rep("hamby comparisons", length(hc_labels)),
    rep("CCFs with lands", length(ccfwl_labels))
  ),
  labels = c(hc_labels, ccfwl_labels)) %>%
    ggplot(aes(x = labels, y = data)) +
    geom_tile() +
    labs(x = "", y = "", title = paste("Comparing labels in variable:", var))  
}
```

The plots below show that the following changes need to be made to `CCFs_withlands_select` in order to match with `hamby_comparison_select`: 
  - study label of `Hamby44` needs to be changed to `Hamby173`
  - lettered barrels need to be changed to `BrUnk` and `Br` needs to be added to other barrels
  - barrel letters need to be made the bullet label and `B` needs to be added to all bullets
  - `L` needs to be added to lands

```{r fig.width = 14, fig.height = 2.5}
plot_labels(var = "study", ccf_data = CCFs_withlands_select)
plot_labels(var = "barrel", ccf_data = CCFs_withlands_select)
plot_labels(var = "bullet", ccf_data = CCFs_withlands_select)
plot_labels(var = "land", ccf_data = CCFs_withlands_select)
```

Determine the letters in the `CCFs_withlands_select` unknown barrels:

```{r}
all_barrel_labels <-
  unique(c(
    as.character(CCFs_withlands_select$barrel1),
    as.character(CCFs_withlands_select$barrel2)
  ))
letters <- all_barrel_labels[!(all_barrel_labels %in% 1:10)]
letters
```

Clean `CCFs_withlands_select` so the labels match `bullet_train_raw`:

```{r}
CCFs_withlands_labelled <- 
  CCFs_withlands_select %>%
  mutate(
    study1 = ifelse(study1 == "Hamby44", "Hamby173", study1),
    study2 = ifelse(study2 == "Hamby44", "Hamby173", study2),
    bullet1 = ifelse(barrel1 %in% letters, barrel1, bullet1),
    barrel1 = ifelse(barrel1 %in% letters, "Unk", barrel1),
    bullet2 = ifelse(barrel2 %in% letters, barrel2, bullet2),
    barrel2 = ifelse(barrel2 %in% letters, "Unk", barrel2)
    ) %>%
  mutate(
    barrel1 = paste0("Br", barrel1),
    bullet1 = paste0("B", bullet1),
    land1 = paste0("L", land1),
    barrel2 = paste0("Br", barrel2),
    bullet2 = paste0("B", bullet2),
    land2 = paste0("L", land2)
  )
```

The plots below show that the labels are now in agreement:

```{r fig.width = 14, fig.height = 2.5}
plot_labels(var = "study", ccf_data = CCFs_withlands_labelled)
plot_labels(var = "barrel", ccf_data = CCFs_withlands_labelled)
plot_labels(var = "bullet", ccf_data = CCFs_withlands_labelled)
plot_labels(var = "land", ccf_data = CCFs_withlands_labelled)
```

## Final Touches

Create the land ids for both datasets:

```{r}
hamby_comparisons <-
  hamby_comparisons_select %>%
  mutate(
    land_id1 = paste(study1, barrel1, bullet1, land1, sep = "-"),
    land_id2 = paste(study2, barrel2, bullet2, land2, sep = "-")
  ) %>%
  select(land_id1, land_id2, all_of(rtrees_features), same_source, flag)

CCFs_withlands <-
  CCFs_withlands_labelled %>%
  mutate(
    land_id1 = paste(study1, barrel1, bullet1, land1, sep = "-"),
    land_id2 = paste(study2, barrel2, bullet2, land2, sep = "-")
  ) %>%
  select(land_id1, land_id2, all_of(rtrees_features), same_source)
```

The structures of the cleaned data:

```{r}
hamby_comparisons %>% str()
CCFs_withlands %>% str()
```

```{r}
length(unique(c(CCFs_withlands$land_id1, CCFs_withlands$land_id2)))
```

# Land ID Differences

This section considers the differences in bullets included in the two datasets. The code below extracts the unique land IDs from the two datasets:

```{r}
hamby_comparisons_ids = unique(c(hamby_comparisons$land_id1, hamby_comparisons$land_id2))
CCFs_withlands_ids = unique(c(CCFs_withlands$land_id1, CCFs_withlands$land_id2))
```

Below are the number of bullets contained in each of the datasets. There are less in `CCFs_withlands` than `hamby_comparisons`:

```{r}
length(hamby_comparisons_ids)
length(CCFs_withlands_ids)
```

Identify the land ID in `CCFs_withlands` but not in `hamby-comparisons`:

```{r}
CCFs_withlands_ids[!(CCFs_withlands_ids %in% hamby_comparisons_ids)]
```

Identify the land ID in `hamby-comparisons` but not in `CCFs_withlands`:

```{r}
hamby_comparisons_ids[!(hamby_comparisons_ids %in% CCFs_withlands_ids)]
```

# Comparisons to rtrees

## Dimensions

One of the aspects which led to the realization that the `hamby-comparisons` data is not the training data for `rtrees` is that the number of observations in the data do not agree with the number of predictions in the `rtrees` model. The number of observations used to train `rtrees` is the following:

```{r}
length(bulletxtrctr::rtrees$predicted)
```

Here are the dimensions of the `hamby_comparisons` data which does not agree with the number of observations used to train `rtrees`:

```{r}
hamby_comparisons %>% dim()
```

Even with the observations removed that are known to have tank rash (`flag != FALSE`), the dimensions of the `hamby_comparisons` data do not agree with `rtrees`:

```{r}
hamby_comparisons %>% filter(flag == FALSE) %>% dim()
```

The code below removes observations based on Eric Hare's code (available [here](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R)), which he thinks may be the code used to train `rtrees`:

```{r}
bullet_train_eric_filter <-
  hamby_comparisons %>%
  separate(col = "land_id1", into = c("study1", "barrel1", "bullet1", "land1")) %>%
  separate(col = "land_id2", into = c("study2", "barrel2", "bullet2", "land2")) %>%
  filter(study1 != "Hamby173" | bullet1 != "BE") %>%
  filter(study2 != "Hamby173" | bullet2 != "BE")

# Eric's code for reference:
# filter(study.y != "Hamby44" | barrel.y != "E") %>%
# filter(study.x != "Hamby44" | barrel.x != "E") %>%
```

Again, the dimensions do not agree with the number of observations in `rtrees`:

```{r}
dim(bullet_train_eric_filter)
length(bulletxtrctr::rtrees$predicted) == dim(bullet_train_eric_filter)[1]
```

In the Hare, Hofmann, and Carriquiry (2017), they describe removing four land impressions that were flagged for quality assessment:

- Barrel 6 Bullet 2-1
- Barrel 9 Bullet 2-4
- Unknown Bullet B-2
- Unknown Bullet Q-4

These lands should correspond to Hamby 252. However, it is possible to obtain the same number of observations as used to train `rtrees` by filtering out observations in `hamby_comparisons` using these barrel, bullet, and land combinations without specifying the study (that is removing observations from both Hamby 173 and Hamby 252).

```{r}
hamby_comparisons_filtered <- 
  hamby_comparisons %>%
  mutate(bbl1 = str_remove(land_id1, pattern = "Hamby252-|Hamby173-"),
         bbl2 = str_remove(land_id2, pattern = "Hamby252-|Hamby173-")) %>%
  filter(!(bbl1 %in% c("Br6-B2-L1", "Br9-B2-L4", "BrUnk-BB-L2", "BrUnk-BQ-L4") | 
           bbl2 %in% c("Br6-B2-L1", "Br9-B2-L4", "BrUnk-BB-L2", "BrUnk-BQ-L4"))) %>%
  select(-bbl1, -bbl2)
hamby_comparisons_filtered %>% dim()
```

While it is possible to use `hamby_comparisons` to get to the same number of observations as `rtrees`, it is only a guess as to how the bullets were removed. On the other hand, the number of rows in `CCFs_withlands` already has the same number of rows as `rtrees`:

```{r}
CCFs_withlands %>% dim()
```

Note that if the code used in Eric Hare's [R script](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R), which he thinks may be the code used to train `rtrees`), is used to filter `CCFs_withlands`, the number of rows does not change!

```{r}
CCFs_withlands %>%
  separate(col = "land_id1", into = c("study1", "barrel1", "bullet1", "land1")) %>%
  separate(col = "land_id2", into = c("study2", "barrel2", "bullet2", "land2")) %>%
  filter(study1 != "Hamby173" | bullet1 != "BE") %>%
  filter(study2 != "Hamby173" | bullet2 != "BE") %>% 
  dim()
```

## Predictions

It is not possible to directly compare the internal predictions from `rtrees` (`predict(bulletxtrctr::rtrees, type = "prob")[,2])`) to those obtained by using `rtrees` to make predictions on the `hamby_comparisons` and `CCFs_withlands` data, because those obtained using the `predict` function from `randomForest` are the out-of-bag (OOB) predictions. The predictions obtained by using the `predict` function from `randomForest` to obtain predictions on a new dataset are created using all the training data. From the documentation for `randomForest:::predict.randomForest`: 

> `newdata`: a data frame or matrix containing new data. (Note: If not given, the out-of-bag prediction in object is returned.

This was determined by Heike based on the following code. She pointed out, "Have a look at the code below - we would expect a line of identity in the last plot. Sorting values also does not help (that would help in case the observations got re-ordered internally in some way). "

```{r}
x1 <- rnorm(1000)
x2 <- rnorm(1000)
x3 <- rnorm(1000)
z <- rbinom(1000,1, 0.4)

dframe <- data.frame(x1,x2,x3,z)

rf1 <- randomForest(factor(z)~x1+x2+x3, data = dframe)

dframe$predict <- predict(rf1, newdata=dframe, type="prob")[,2]
dframe$rfscore <- predict(rf1, type="prob")[,2]

dframe %>% 
  ggplot(aes(x = predict, y = rfscore)) + geom_point()
```

However, we may still gain some insights by comparing the distributions of the predictions. The code below extracts the predictions on the training data from `rtrees` and uses `rtrees` to make predictions on `hamby_comparisons` and `CCFs_withlands`:

```{r}
rtrees_pred = predict(bulletxtrctr::rtrees, type = "prob")[,2]
hc_pred = predict(bulletxtrctr::rtrees, hamby_comparisons %>% select(rtrees_features), type = "prob")[,2]
ccfwl_pred = predict(bulletxtrctr::rtrees, CCFs_withlands %>% select(rtrees_features), type = "prob")[,2]

all_pred <-
  data.frame(
    dataset = c(
      rep("internal", length(rtrees_pred)),
      rep("Hamby comparisons", length(hc_pred)),
      rep("CCFs with lands", length(ccfwl_pred))
    ),
    pred = c(rtrees_pred, hc_pred, ccfwl_pred)
  )
```

Plot showing distributions of three set of predictions from `rtrees`: (light blue) internal predictions from `rtrees`, (blue) predictions obtained by applying `rtrees` to the observations in the `CCFs_withlands` data, and (purple) predictions obtained by applying `rtrees` to the observations in the `hamby_comparisons` data. Note that even though the internal predictions from `rtrees` are OOB and those computed using `CCFs_withlands` are not OOB, the distributions are very similar. On the other hand, the predictions from `hamby_comparions` are very different. This provides evidence that `rtrees` was trained on `CCFs_withlands`, and the change in units of `D` and `sd_D` in `hamby_comparisons` is apparent by the much different distribution of predictions from `rtrees`:

```{r}
all_pred %>%
  ggplot(aes(x = pred, fill = dataset, color = dataset)) +
  geom_density(alpha = 0.5, size = 1) +
  scale_fill_manual(values = c("blue", "purple", "lightblue")) + 
  scale_color_manual(values = c("blue", "purple", "lightblue")) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "rtrees predictions",
       y = "Density",
       fill = "Data predictions computed on",
       color = "Data predictions computed on")
```
The four plots below show direct comparisons of predictions between the internal `rtrees` predictions and those computed on `hamby_comparisons` and `CCFs_withlands` using `rtrees`. There are two versions of the plots for each of the possible training datasets. One plots the predictions without adjusting the order of the predictions in any way. The other plot sorts the predictions from lowest to highest (for a dataset) in case it helps to see a direct relationship. None of the figures show a 1-to-1 relationship, but notice that the plot with the title "Comparing internal to CCFs with lands (not sorted)" looks very similar to the one created by Heike with the example data and random forest. This is additional evidence that `CCFs_withlands` was used to train `rtrees` since even without sorting the predictions, the relationship between the OOB and new predictions is very similar to an example where we know the same training data was used.

```{r fig.width = 12, fig.height = 10}
plot_grid(
  all_pred %>%
    filter(dataset != "CCFs with lands") %>%
    group_by(dataset) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `Hamby comparisons`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to Hamby Comparisons (not sorted)"),
  all_pred %>%
    filter(dataset != "CCFs with lands") %>%
    group_by(dataset) %>%
    arrange(pred) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `Hamby comparisons`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to Hamby Comparisons (sorted)"),
  all_pred %>%
    filter(dataset != "Hamby comparisons") %>%
    group_by(dataset) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `CCFs with lands`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to CCFs with lands (not sorted)"), 
  all_pred %>%
    filter(dataset != "Hamby comparisons") %>%
    group_by(dataset) %>%
    arrange(pred) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `CCFs with lands`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to CCFs with lands (sorted)")
)
```

# Training New Random Forests

In this section, we retrain various random forest models using both the Hamby comparison and CCFs with lands data. Then we compare the results from the retrained models to `rtrees` to check for similarity. The results show that the retrained models on the CCFs with lands data are very similar to `rtrees` while the model trained on the Hamby comparison data are very different. It should be noted that all models trained in this section on the Hamby comparison data used the observations in the filtered version of the dataset (`hamby_comparisons_filtered`) so that the number of observations match `rtrees` and since this was the data we were previously using in the LIME diagnostics paper.

## Old Seeds

Unfortunately, the seed that was used to train `rtrees` was lost or the changes in the way the random number generation is done in R has changed has made it not possible to reproduce `rtrees`. However, Heike has two seeds that were used around the time of training `rtrees`
The seeds used were selected by Heike based on ones she believes were used at the time of training `rtrees`: 20140501 and 20170222. Note that 20170222 is also the seed used in Eric's [code](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R).

Below, four random forest models are trained using the seeds suggested by Heike. The code used to fit the models is based on Eric's [code](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R), which is believed to be the code used to train the original `rtrees`. The first two random forest are fit using `CCFs_withlands`, and the third and fourth models are fit using `hamby_comparisons_filtered`: 

```{r}
rtrees2_file = "../../../data/rfs_rtrees2.rds"
if (!file.exists(rtrees2_file)) {
  set.seed(20140501)
  rtrees2 <-
    randomForest(
      factor(same_source) ~ ., 
      data = CCFs_withlands %>% select(rtrees_features, same_source), 
      ntree = 300
    )
  saveRDS(object = rtrees2, file = rtrees2_file)
} 

rtrees3_file = "../../../data/rfs_rtrees3.rds"
if (!file.exists(rtrees3_file)) {
  set.seed(20170222)
  rtrees3 <-
    randomForest(
      factor(same_source) ~ ., 
      data = CCFs_withlands %>% select(rtrees_features, same_source), 
      ntree = 300
    )
  saveRDS(object = rtrees3, file = rtrees3_file)
} 

rtrees4_file = "../../../data/rfs_rtrees4.rds"
if (!file.exists(rtrees4_file)) {
  set.seed(20140501)
  rtrees4 <-
    randomForest(
      factor(same_source) ~ .,
      data = hamby_comparisons_filtered %>% select(rtrees_features, same_source),
      ntree = 300
    )
  saveRDS(object = rtrees4, file = rtrees4_file)
}

rtrees5_file = "../../../data/rfs_rtrees5.rds"
if (!file.exists(rtrees5_file)) {
  set.seed(20170222)
  rtrees5 <-
    randomForest(
      factor(same_source) ~ .,
      data = hamby_comparisons_filtered %>% select(rtrees_features, same_source),
      ntree = 300
    )
  saveRDS(object = rtrees5, file = rtrees5_file)
} 
```

Load the saved versions of the models:

```{r}
rtrees2 <- readRDS(rtrees2_file)
rtrees3 <- readRDS(rtrees3_file)
rtrees4 <- readRDS(rtrees4_file)
rtrees5 <- readRDS(rtrees5_file)
```

Extract the votes from each of the newly trained random forest models and `rtrees` and prepare the dataframe for plotting: 

```{r}
rtrees_votes <-
  data.frame(
    rtrees = bulletxtrctr::rtrees$votes,
    rtrees2 = rtrees2$votes,
    rtrees3 = rtrees3$votes,
    rtrees4 = rtrees4$votes,
    rtrees5 = rtrees5$votes
  ) %>%
  mutate(obs = 1:n()) %>%
  pivot_longer(cols = -obs) %>%
  separate(name, c("model", "label")) %>%
  pivot_wider(names_from = model, values_from = value)
```

Plots comparing the votes from `rtrees` to those from the newly trained models. The top row contains the comparisons with the random forests trained on `CCFs_withlands`. Note that the first two plots comparing the `CCFs_withlands` newly trained random forest vote to `rtrees` looks very similar to the third plots which compares the votes from the two newly trained random forests on `CCFs_withlands`. This suggests that even though all three models are trained using different seeds, the training data is the same. On the other hand, the bottom row of plots are created using the votes from the random forests trained on `hamby_comparisons_filtered`, and the two plots comparing the votes to `rtrees` look very different from the third plot comparing the votes from the two newly trained models. This suggests that the `hamby_comparisons_filtered` was not the training data for `rtrees`, or at least, the observations are not ordered the same in the dataset.

```{r fig.width = 12, fig.height = 5}
plot_grid(
  rtrees_votes %>%
    ggplot(aes(
      x = rtrees, y = rtrees2, color = label
    )) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees2 votes",
         title = "Retrained RF on Hamby comparison data versus rtrees; Seed 20140501"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = rtrees, y = rtrees3, color = label
    )) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees3 votes",
         title = "Retrained RF on Hamby comparison data versus rtrees; Seed 20170222"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = rtrees2, y = rtrees3, color = label
    )) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees2 votes",
         title = "Both retrained RFs on Hamby comparison data"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = rtrees, y = rtrees4, color = label
    )) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees4 votes",
         title = "Retrained RF on CCFs with lands data versus rtrees; Seed 20140501"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = rtrees, y = rtrees5, color = label
    )) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees5 votes",
         title = "Retrained RF on CCFs with lands data versus rtrees; Seed 20170222"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = rtrees4, y = rtrees5, color = label
    )) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees5 votes",
         title = "Both retrained RFs on CCFs with lands data"),
  nrow = 2
)
```

To address the issue that the observations in `CCFs_withlands` and `hamby_comparisons` may not be ordered the same way as the training data for `rtrees`, the set of plots are recreated by first ordering all votes. If the training data and seed are the same as those used to train `rtrees`, we would expect a 1-to-1 relationship. 1-to-1 lines are included in the plots, and none of the votes result in an exact 1-to-1 relationship.

```{r fig.width = 12, fig.height = 5}
plot_grid(
  rtrees_votes %>%
    ggplot(aes(
      x = sort(rtrees), y = sort(rtrees2), color = label
    )) +
    geom_abline(slope = 1, intercept = 0) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees2 votes",
         title = "Retrained RF on Hamby comparison data versus rtrees; Seed 20140501"),
  
  rtrees_votes%>%
    ggplot(aes(
      x = sort(rtrees), y = sort(rtrees3), color = label
    )) +
    geom_abline(slope = 1, intercept = 0) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees3 votes",
         title = "Retrained RF on Hamby comparison data versus rtrees; Seed 20170222"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = sort(rtrees2), y = sort(rtrees3), color = label
    )) +
    geom_abline(slope = 1, intercept = 0) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees2 votes",
         title = "Both retrained RFs on Hamby comparison data"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = sort(rtrees), y = sort(rtrees4), color = label
    )) +
    geom_abline(slope = 1, intercept = 0) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees4 votes",
         title = "Retrained RF on CCFs with lands data versus rtrees; Seed 20140501"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = sort(rtrees), y = sort(rtrees5), color = label
    )) +
    geom_abline(slope = 1, intercept = 0) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees5 votes",
         title = "Retrained RF on CCFs with lands data versus rtrees; Seed 20170222"),
  
  rtrees_votes %>%
    ggplot(aes(
      x = sort(rtrees4), y = sort(rtrees5), color = label
    )) +
    geom_abline(slope = 1, intercept = 0) +
    geom_point(shape = 1) +
    labs(x = "rtrees votes",
         y = "rtrees5 votes",
         title = "Both retrained RFs on CCFs with lands data"),
  nrow = 2
)
```

The confusion matrices from `rtrees` and the four newly trained random forests (note that the models trained using `CCFs_withlands` result in much more similar confusion matrices to `rtrees` than the models trained using `hamby_comparisons_filtered`): 

```{r}
bulletxtrctr::rtrees$confusion
rtrees2$confusion
rtrees3$confusion
rtrees4$confusion
rtrees5$confusion
```

## Distribution Across Seeds

To better understand how the random forests trained on `CCFs_withlands` and `hamby_comparisons` compare to `rtrees`, we compare the true and false class errors from `rtrees` to the distributions of the class errors by train 250 new random forests using different seeds.

### Training the Random Forests

Randomly select 100 seeds (using a random seed): 

```{r}
set.seed(20200925)
seeds = sample(x = 10000000:100000000, size = 250, replace = FALSE)
seeds
```

Function for fitting random forests to mimic rtrees with different seeds:

```{r}
fit_rf <- function(seed, dataset) {
  set.seed(seed)
  randomForest(
    y = factor(dataset$same_source),
    x = dataset %>% select(all_of(rtrees_features)),
    ntree = bulletxtrctr::rtrees$ntree,
    mtry = bulletxtrctr::rtrees$mtry
  )
}
```

Fit 250 new random forests on `hamby_comparisons_filtered` and `CCFs_withlands` using the seeds generated above:

```{r}
rfs_hc_file = "../../../data/rfs_hamby_comparison.rds"
if (!file.exists(rfs_hc_file)) {
  saveRDS(
    object = map(.x = seeds, .f = fit_rf, dataset = hamby_comparisons_filtered),
    file = rfs_hc_file
  )
} 
rfs_ccfwl_file = "../../../data/rfs_CCFs_withlands.rds"
if (!file.exists(rfs_ccfwl_file)) {
  saveRDS(
    object = map(.x = seeds, .f = fit_rf, dataset = CCFs_withlands),
    file = rfs_ccfwl_file
  )
}
```

Load the saved versions of the random forest models: 

```{r}
rfs_hamby_comparison = readRDS(rfs_hc_file)
rfs_CCFs_withlands = readRDS(rfs_ccfwl_file)
```

### Extracting Model Results

Function for extracting the confusion matrices from the model and put in a nice data frame:

```{r}
extract_confus <- function(model) {
  data.frame(model$confusion) %>%
    rename("FALSE" = "FALSE.", "TRUE" = "TRUE.", "class_error" = "class.error") %>%
    mutate(observed = rownames(model$confusion)) %>%
    pivot_wider(names_from = observed, values_from = everything())  
}
```

Extract the confusion matrices and importance values from all random forest models:

```{r}
hamby_comparison_confus <-
  map_df(.x = rfs_hamby_comparison, .f = extract_confus, .id = "rf_model_id")
CCFs_withlands_confus <-
  map_df(.x = rfs_CCFs_withlands, .f = extract_confus, .id = "rf_model_id")
```

Function for extracting the importance values, computing the rank of the features based on importance, and putting in a data frame: 

```{r}
extract_importance <- function(model) {
  data.frame(model$importance) %>%
    mutate(features = rownames(model$importance)) %>%
    arrange(desc(MeanDecreaseGini)) %>%
    mutate(rank = 1:n()) %>%
    rename("importance" = "MeanDecreaseGini") %>%
    select(features, importance, rank)
}
```

Extract the feature importance from the new models: 

```{r}
hamby_comparison_importance <-
  map_df(.x = rfs_hamby_comparison, .f = extract_importance, .id = "rf_model_id")
CCFs_withlands_importance <-
  map_df(.x = rfs_CCFs_withlands, .f = extract_importance, .id = "rf_model_id")
```

Extract the feature importance from `rtrees`:

```{r}
rtrees_importance <- 
  data.frame(features = rownames(bulletxtrctr::rtrees$importance),
             bulletxtrctr::rtrees$importance) %>%
  arrange(desc(MeanDecreaseGini)) %>%
  mutate(rank = 1:n(),
         rf_model_id = "rtrees") %>%
  rename("importance" = "MeanDecreaseGini") %>%
  select(rf_model_id, features, importance, rank)
```

### Class Error Distributions

Obtain the class errors from `rtrees` and the paper random forest:

```{r}
rtrees_values <-
  data.frame(
    model = "rtrees",
    class_error_true = bulletxtrctr::rtrees$confusion[2, 3],
    class_error_false = bulletxtrctr::rtrees$confusion[1, 3]
  )
```

Histograms of the class errors (true and false) show that the rtrees values appear to be in the extreme (false) or outside of the new random forest models (true):

```{r fig.width = 10, fig.height = 4.5}
hist_true_hc <-
  hamby_comparison_confus %>%
  ggplot(aes(x = class_error_TRUE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_true, color = model))

hist_false_hc <- 
  hamby_comparison_confus %>%
  ggplot(aes(x = class_error_FALSE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_false, color = model))

hist_true_ccfwl <-
  CCFs_withlands_confus %>%
  ggplot(aes(x = class_error_TRUE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_true, color = model))

hist_false_ccfwl <- 
  CCFs_withlands_confus %>%
  ggplot(aes(x = class_error_FALSE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_false, color = model))

plot_grid(hist_true_hc, hist_false_hc, hist_true_ccfwl, hist_false_ccfwl)
```

### Comparing Feature Importance

Heatmap depicting feature importance across models: 

```{r fig.width = 12, fig.height = 5}
plot_grid(
  bind_rows(rtrees_importance, hamby_comparison_importance) %>%
    mutate(
      rf_model_id = factor(rf_model_id, levels = c("rtrees", 1:length(seeds))),
      rank = factor(rank, levels = 1:9),
      features = factor(features, levels = rev(rtrees_importance$features))
    ) %>%
    ggplot(aes(x = rf_model_id, y = features, fill = rank)) +
    geom_tile() +
    scale_fill_brewer(palette = "RdYlBu") + 
    theme_bw() +
    labs(
      x = "Random Forest Model", 
      y = "Feature", 
      title = "Comparing rtrees importance to random forests fit using Hamby comparisons data"
    ),
  
  bind_rows(rtrees_importance, CCFs_withlands_importance) %>%
    mutate(
      rf_model_id = factor(rf_model_id, levels = c("rtrees", 1:length(seeds))),
      rank = factor(rank, levels = 1:9),
      features = factor(features, levels = rev(rtrees_importance$features))
    ) %>%
    ggplot(aes(x = rf_model_id, y = features, fill = rank)) +
    geom_tile() +
    scale_fill_brewer(palette = "RdYlBu") + 
    theme_bw() +
    labs(
      x = "Random Forest Model", 
      y = "Feature", 
      title = "Comparing rtrees importance to random forests fit using CCFs with lands data"
    )
)
```

```{r fig.width = 12, fig.height = 5}
plot_grid(
  bind_rows(rtrees_importance, hamby_comparison_importance) %>%
    mutate(
      rf_model_id = factor(rf_model_id, levels = c("rtrees", 1:length(seeds))),
      rank = factor(rank, levels = 1:9),
      features = factor(features, levels = rev(rtrees_importance$features)),
      rtrees_ind = ifelse(rf_model_id == "rtrees", "rtrees", "Hamby Comparison")
    ) %>%
    ggplot(aes(x = rank, y = features, group = rf_model_id, color = rtrees_ind)) +
    geom_point(alpha = 0.5, shape = 1) + 
    geom_line(alpha = 0.5) +
    scale_color_manual(values = c("grey50", "blue")) +
    theme_bw() +
    labs(
      x = "Random Forest Model", 
      y = "Feature", 
      title = "Comparing rtrees importance to random forests fit using Hamby comparisons data"
    ), 
    bind_rows(rtrees_importance, CCFs_withlands_importance) %>%
    mutate(
      rf_model_id = factor(rf_model_id, levels = c("rtrees", 1:length(seeds))),
      rank = factor(rank, levels = 1:9),
      features = factor(features, levels = rev(rtrees_importance$features)),
      rtrees_ind = ifelse(rf_model_id == "rtrees", "rtrees", "CCFs with lands")
    ) %>%
    ggplot(aes(x = rank, y = features, group = rf_model_id, color = rtrees_ind)) +
    geom_point(alpha = 0.5, shape = 1) + 
    geom_line(alpha = 0.5) +
    scale_color_manual(values = c("grey50", "blue")) +
    theme_bw() +
    labs(
      x = "Random Forest Model", 
      y = "Feature", 
      title = "Comparing rtrees importance to random forests fit using CCFs with lands data"
    )
)
```

# Session Info

```{r}
sessionInfo()
```
