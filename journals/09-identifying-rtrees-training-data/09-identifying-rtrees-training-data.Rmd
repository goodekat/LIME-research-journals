---
title: "Identifying `rtrees` Training Data"
author: "Katherine Goode"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    theme: cerulean
    highlight: textmate
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  eval = TRUE,
  cache = FALSE, 
  dpi = 300
)
```

This journal contains work to identify the data used to train `rtrees` (contained in both `bulletr` and `bulletxtrctr`). We recently discovered some discrepancies between `rtrees` and the training data we were using (`hamby-comparisons.csv`, previously `features-hamby173and252.csv`). Unfortunately, the original work by Eric is not well documented, so it is difficult to know for sure which dataset was used to train the model. However, Eric recently pointed us to some [code](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R), which he believes was used to train `rtrees`. Heike was able to rerun part of the code to extract data from the CSAFE database that was created by the first part of the code (scans to features). The new data (`CCFs_withlands.csv`) contains the same number of rows the number of predictions associated with `rtrees`. I have gathered all of our work trying to determine that `CCFs_withlands` is the data used to train `rtrees` in this journal.

```{r}
library(cowplot)
library(dplyr)
library(ggplot2)
library(purrr)
library(randomForest)
library(stringr)
library(tidyr)
```

# Raw Datasets

This section contains code for loading and performing initial comparisons of the raw datasets.

## Load Data

Load the data provided by Heike and CSAFE that we have been using and believed to be the training data for rtrees:

```{r}
hamby_comparisons_raw <- read.csv("../../../data/raw/hamby-comparisons.csv")
```

Load the data extracted (on 2020-09-23) from the CSAFE database and corresponds to the [R script](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R) Eric believes to be the one used to train `rtrees`.

```{r}
CCFs_withlands_raw <- read.csv("../../../data/raw/CCFs_withlands.csv")
```

Obtain the features used to train `rtrees` for use throughout this journal:

```{r}
rtrees_features <- rownames(bulletxtrctr::rtrees$importance)
```

## Initial Comparisons

Dimensions of the raw datasets:

```{r}
dim(hamby_comparisons_raw)
dim(CCFs_withlands_raw)
```

Note that `CCFs_withlands` has the same number of rows as the number of predictions associated with `rtrees`:

```{r}
length(bulletxtrctr::rtrees$predicted)
```

Comparing summaries of the distributions of the features used to train `rtrees` from the two datasets. Note that the main differences are seen with the distributions of `D` (distance) and `sd_D` (standard deviation of distance):

```{r}
summary(hamby_comparisons_raw %>% select(all_of(rtrees_features)))
summary(CCFs_withlands_raw %>% select(all_of(rtrees_features)))
```

This result is even true when the observations in `hamby_comparisons` known to have tank rash (`flag == FALSE`) are removed. This seems to suggest that the units of `D` and `sd_D` changed from `CCFs_withlands`:  

```{r}
summary(hamby_comparisons_raw %>% filter(flag == FALSE) %>% select(all_of(rtrees_features)))
```

Comparing visualizations of the distributions of the features used to train `rtrees` from the two datasets to again see the differences in distributions of `D` and `sd_D`:

```{r fig.width = 10, fig.height = 3}
bind_rows(
  hamby_comparisons_raw %>%
    filter(flag == FALSE) %>%
    select(all_of(rtrees_features)) %>%
    pivot_longer(cols = everything()) %>%
    mutate(dataset = "hamby_comparisons"),
  CCFs_withlands_raw %>% select(all_of(rtrees_features)) %>%
    pivot_longer(cols = everything()) %>%
    mutate(dataset = "CCFs_withlands")
) %>%
  ggplot(aes(x = value, fill = dataset)) + 
  geom_histogram() +
  facet_grid(dataset ~ name)
```

# Data Cleaning

There are discrepancies in the naming conventions of the two datasets. This section contains the code that identifies the differences and cleans the data.

## Extracting Variables of Interest

The following variables are contained in the raw versions of the data. Note that they have different variables and different names. For our analysis, we only need the variables identifying the lands, the features used to train `rtrees`, the ground truth for whether or not the bullets are a match, and variables flagging bullets with tank rash.

```{r}
names(hamby_comparisons_raw)
names(CCFs_withlands_raw)
```

The code below separates the land id variables in `hamby_comparisons_raw` into separate columns for study, barrel, bullet, and land and selects only the variables of interest. 

```{r}
hamby_comparisons_select <- 
  hamby_comparisons_raw %>%
  separate(land_id1, c("study1", "barrel1", "bullet1", "land1")) %>%
  separate(land_id2, c("study2", "barrel2", "bullet2", "land2")) %>%
  select(
    study1,
    barrel1,
    bullet1,
    land1,
    study2,
    barrel2,
    bullet2,
    land2,
    all_of(rtrees_features),
    same_source,
    flag
  )
```

The code below renames some of the variables in `CCFs_withlands_raw`, selects only the variables of interest, and converts all land labels to characters.

```{r}
CCFs_withlands_select <- 
  CCFs_withlands_raw %>%
  rename(
    "study1" = "study.x",
    "barrel1" = "barrel.x",
    "bullet1" = "bullet.x",
    "land1" = "land.x",
    "study2" = "study.y",
    "barrel2" = "barrel.y",
    "bullet2" = "bullet.y",
    "land2" = "land.y",
    "same_source"= "match"
  ) %>%
  select(
    study1,
    barrel1,
    bullet1,
    land1,
    study2,
    barrel2,
    bullet2,
    land2,
    all_of(rtrees_features),
    same_source
  ) %>%
  mutate(across(c(barrel1, bullet1, land1, barrel2, bullet2, land2), as.character))
```

Check to make sure the structures of the two datasets agree:

```{r}
hamby_comparisons_select %>% str()
CCFs_withlands_select %>% str()
```

## Matching Labels

The function below extracts the labels from the two datasets for a given variable name `var` and creates a plot to show the discrepancies between `hamby_comparison_select` and `CCFs_withlands_select`.

```{r}
plot_labels <- function(var, ccf_data) {
  
  # Extract the labels
  hc_labels <-
    unique(c(
      hamby_comparisons_select %>% pull(paste0(var, "1")),
      hamby_comparisons_select %>% pull(paste0(var, "2"))
    ))
  ccfwl_labels <-
    unique(c(
      ccf_data %>% pull(paste0(var, "1")),
      ccf_data %>% pull(paste0(var, "2"))
    ))

  # Plot the labels
  data.frame(data = c(
    rep("hamby comparisons", length(hc_labels)),
    rep("CCFs with lands", length(ccfwl_labels))
  ),
  labels = c(hc_labels, ccfwl_labels)) %>%
    ggplot(aes(x = labels, y = data)) +
    geom_tile() +
    labs(x = "", y = "", title = paste("Comparing labels in variable:", var))  
}
```

The plots below show that the following changes need to be made to `CCFs_withlands_select` in order to match with `hamby_comparison_select`: 
  - study label of `Hamby44` needs to be changed to `Hamby173`
  - lettered barrels need to be changed to `BrUnk` and `Br` needs to be added to other barrels
  - barrel letters need to be made the bullet label and `B` needs to be added to all bullets
  - `L` needs to be added to lands

```{r fig.width = 14, fig.height = 2.5}
plot_labels(var = "study", ccf_data = CCFs_withlands_select)
plot_labels(var = "barrel", ccf_data = CCFs_withlands_select)
plot_labels(var = "bullet", ccf_data = CCFs_withlands_select)
plot_labels(var = "land", ccf_data = CCFs_withlands_select)
```

Determine the letters in the `CCFs_withlands_select` unknown barrels:

```{r}
all_barrel_labels <-
  unique(c(
    as.character(CCFs_withlands_select$barrel1),
    as.character(CCFs_withlands_select$barrel2)
  ))
letters <- all_barrel_labels[!(all_barrel_labels %in% 1:10)]
letters
```

Clean `CCFs_withlands_select` so the labels match `bullet_train_raw`:

```{r}
CCFs_withlands_labelled <- 
  CCFs_withlands_select %>%
  mutate(
    study1 = ifelse(study1 == "Hamby44", "Hamby173", study1),
    study2 = ifelse(study2 == "Hamby44", "Hamby173", study2),
    bullet1 = ifelse(barrel1 %in% letters, barrel1, bullet1),
    barrel1 = ifelse(barrel1 %in% letters, "Unk", barrel1),
    bullet2 = ifelse(barrel2 %in% letters, barrel2, bullet2),
    barrel2 = ifelse(barrel2 %in% letters, "Unk", barrel2)
    ) %>%
  mutate(
    barrel1 = paste0("Br", barrel1),
    bullet1 = paste0("B", bullet1),
    land1 = paste0("L", land1),
    barrel2 = paste0("Br", barrel2),
    bullet2 = paste0("B", bullet2),
    land2 = paste0("L", land2)
  )
```

The plots below show that the labels are now in agreement:

```{r fig.width = 14, fig.height = 2.5}
plot_labels(var = "study", ccf_data = CCFs_withlands_labelled)
plot_labels(var = "barrel", ccf_data = CCFs_withlands_labelled)
plot_labels(var = "bullet", ccf_data = CCFs_withlands_labelled)
plot_labels(var = "land", ccf_data = CCFs_withlands_labelled)
```

## Final Touches

Create the land ids for both datasets:

```{r}
hamby_comparisons <-
  hamby_comparisons_select %>%
  mutate(
    land_id1 = paste(study1, barrel1, bullet1, land1, sep = "-"),
    land_id2 = paste(study2, barrel2, bullet2, land2, sep = "-")
  ) %>%
  select(land_id1, land_id2, all_of(rtrees_features), same_source, flag)

CCFs_withlands <-
  CCFs_withlands_labelled %>%
  mutate(
    land_id1 = paste(study1, barrel1, bullet1, land1, sep = "-"),
    land_id2 = paste(study2, barrel2, bullet2, land2, sep = "-")
  ) %>%
  select(land_id1, land_id2, all_of(rtrees_features), same_source)
```

The structures of the cleaned data:

```{r}
hamby_comparisons %>% str()
CCFs_withlands %>% str()
```

```{r}
length(unique(c(CCFs_withlands$land_id1, CCFs_withlands$land_id2)))
```

# Land ID Differences

This section considers the differences in bullets included in the two datasets. The code below extracts the unique land IDs from the two datasets:

```{r}
hamby_comparisons_ids = unique(c(hamby_comparisons$land_id1, hamby_comparisons$land_id2))
CCFs_withlands_ids = unique(c(CCFs_withlands$land_id1, CCFs_withlands$land_id2))
```

Below are the number of bullets contained in each of the datasets. There are less in `CCFs_withlands` than `hamby_comparisons`:

```{r}
length(hamby_comparisons_ids)
length(CCFs_withlands_ids)
```

Identify the land ID in `CCFs_withlands` but not in `hamby-comparisons`:

```{r}
CCFs_withlands_ids[!(CCFs_withlands_ids %in% hamby_comparisons_ids)]
```

Identify the land ID in `hamby-comparisons` but not in `CCFs_withlands`:

```{r}
hamby_comparisons_ids[!(hamby_comparisons_ids %in% CCFs_withlands_ids)]
```

# Comparisons to rtrees

## Dimensions

One of the aspects which led to the realization that the `hamby-comparisons` data is not the training data for `rtrees` is that the number of observations in the data do not agree with the number of predictions in the `rtrees` model. The number of observations used to train `rtrees` is the following:

```{r}
length(bulletxtrctr::rtrees$predicted)
```

Here are the dimensions of the `hamby_comparisons` data which does not agree with the number of observations used to train `rtrees`:

```{r}
hamby_comparisons %>% dim()
```

Even with the observations removed that are known to have tank rash (`flag != FALSE`), the dimensions of the `hamby_comparisons` data do not agree with `rtrees`:

```{r}
hamby_comparisons %>% filter(flag == FALSE) %>% dim()
```

The code below removes observations based on Eric Hare's code (available [here](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R)), which he thinks may be the code used to train `rtrees`:

```{r}
bullet_train_eric_filter <-
  hamby_comparisons %>%
  separate(col = "land_id1", into = c("study1", "barrel1", "bullet1", "land1")) %>%
  separate(col = "land_id2", into = c("study2", "barrel2", "bullet2", "land2")) %>%
  filter(study1 != "Hamby173" | bullet1 != "BE") %>%
  filter(study2 != "Hamby173" | bullet2 != "BE")

# Eric's code for reference:
# filter(study.y != "Hamby44" | barrel.y != "E") %>%
# filter(study.x != "Hamby44" | barrel.x != "E") %>%
```

Again, the dimensions do not agree with the number of observations in `rtrees`:

```{r}
dim(bullet_train_eric_filter)
length(bulletxtrctr::rtrees$predicted) == dim(bullet_train_eric_filter)[1]
```

In the Hare, Hofmann, and Carriquiry (2017), they describe removing four land impressions that were flagged for quality assessment:

- Barrel 6 Bullet 2-1
- Barrel 9 Bullet 2-4
- Unknown Bullet B-2
- Unknown Bullet Q-4

These lands should correspond to Hamby 252. However, it is possible to obtain the same number of observations as used to train `rtrees` by filtering out observations in `hamby_comparisons` using these barrel, bullet, and land combinations without specifying the study (that is removing observations from both Hamby 173 and Hamby 252).

```{r}
hamby_comparisons_filtered <- 
  hamby_comparisons %>%
  mutate(bbl1 = str_remove(land_id1, pattern = "Hamby252-|Hamby173-"),
         bbl2 = str_remove(land_id2, pattern = "Hamby252-|Hamby173-")) %>%
  filter(!(bbl1 %in% c("Br6-B2-L1", "Br9-B2-L4", "BrUnk-BB-L2", "BrUnk-BQ-L4") | 
           bbl2 %in% c("Br6-B2-L1", "Br9-B2-L4", "BrUnk-BB-L2", "BrUnk-BQ-L4"))) %>%
  select(-bbl1, -bbl2)
hamby_comparisons_filtered %>% dim()
```

While it is possible to use `hamby_comparisons` to get to the same number of observations as `rtrees`, it is only a guess as to how the bullets were removed. On the other hand, the number of rows in `CCFs_withlands` already has the same number of rows as `rtrees`:

```{r}
CCFs_withlands %>% dim()
```

Note that if the code used in Eric Hare's [R script](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R), which he thinks may be the code used to train `rtrees`), is used to filter `CCFs_withlands`, the number of rows does not change!

```{r}
CCFs_withlands %>%
  separate(col = "land_id1", into = c("study1", "barrel1", "bullet1", "land1")) %>%
  separate(col = "land_id2", into = c("study2", "barrel2", "bullet2", "land2")) %>%
  filter(study1 != "Hamby173" | bullet1 != "BE") %>%
  filter(study2 != "Hamby173" | bullet2 != "BE") %>% dim()
```

## Predictions

It is not possible to directly compare the internal predictions from `rtrees` (`predict(bulletxtrctr::rtrees, type = "prob")[,2])`) to those obtained by using `rtrees` to make predictions on the `hamby_comparisons` and `CCFs_withlands` data, because those obtained using the `predict` function from `randomForest` are the out-of-bag (OOB) predictions. The predictions obtained by using the `predict` function from `randomForest` to obtain predictions on a new dataset are created using all the training data. From the documentation for `randomForest:::predict.randomForest`: 

> `newdata`: a data frame or matrix containing new data. (Note: If not given, the out-of-bag prediction in object is returned.

This was determined by Heike based on the following code. She pointed out, "Have a look at the code below - we would expect a line of identity in the last plot. Sorting values also does not help (that would help in case the observations got re-ordered internally in some way). "

```{r}
x1 <- rnorm(1000)
x2 <- rnorm(1000)
x3 <- rnorm(1000)
z <- rbinom(1000,1, 0.4)

dframe <- data.frame(x1,x2,x3,z)

rf1 <- randomForest(factor(z)~x1+x2+x3, data = dframe)

dframe$predict <- predict(rf1, newdata=dframe, type="prob")[,2]
dframe$rfscore <- predict(rf1, type="prob")[,2]

dframe %>% 
  ggplot(aes(x = predict, y = rfscore)) + geom_point()
```

However, we may still gain some insights by comparing the distributions of the predictions. The code below extracts the predictions on the training data from `rtrees` and uses `rtrees` to make predictions on `hamby_comparisons` and `CCFs_withlands`:

```{r}
rtrees_pred = predict(bulletxtrctr::rtrees, type = "prob")[,2]
hc_pred = predict(bulletxtrctr::rtrees, hamby_comparisons %>% select(rtrees_features), type = "prob")[,2]
ccfwl_pred = predict(bulletxtrctr::rtrees, CCFs_withlands %>% select(rtrees_features), type = "prob")[,2]

all_pred <-
  data.frame(
    dataset = c(
      rep("internal", length(rtrees_pred)),
      rep("Hamby comparisons", length(hc_pred)),
      rep("CCFs with lands", length(ccfwl_pred))
    ),
    pred = c(rtrees_pred, hc_pred, ccfwl_pred)
  )
```

Plot showing distributions of three set of predictions from `rtrees`: (light blue) internal predictions from `rtrees`, (blue) predictions obtained by applying `rtrees` to the observations in the `CCFs_withlands` data, and (purple) predictions obtained by applying `rtrees` to the observations in the `hamby_comparisons` data. Note that even though the internal predictions from `rtrees` are OOB and those computed using `CCFs_withlands` are not OOB, the distributions are very similar. On the other hand, the predictions from `hamby_comparions` are very different. This provides evidence that `rtrees` was trained on `CCFs_withlands`, and the change in units of `D` and `sd_D` in `hamby_comparisons` is apparent by the much different distribution of predictions from `rtrees`:

```{r}
all_pred %>%
  ggplot(aes(x = pred, fill = dataset, color = dataset)) +
  geom_density(alpha = 0.5, size = 1) +
  scale_fill_manual(values = c("blue", "purple", "lightblue")) + 
  scale_color_manual(values = c("blue", "purple", "lightblue")) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "rtrees predictions",
       y = "Density",
       fill = "Data predictions computed on",
       color = "Data predictions computed on")
```
The four plots below show direct comparisons of predictions between the internal `rtrees` predictions and those computed on `hamby_comparisons` and `CCFs_withlands` using `rtrees`. There are two versions of the plots for each of the possible training datasets. One plots the predictions without adjusting the order of the predictions in any way. The other plot sorts the predictions from lowest to highest (for a dataset) in case it helps to see a direct relationship. None of the figures show a 1-to-1 relationship, but notice that the plot with the title "Comparing internal to CCFs with lands (not sorted)" looks very similar to the one created by Heike with the example data and random forest. This is additional evidence that `CCFs_withlands` was used to train `rtrees` since even without sorting the predictions, the relationship between the OOB and new predictions is very similar to an example where we know the same training data was used.

```{r fig.width = 12, fig.height = 10}
plot_grid(
  all_pred %>%
    filter(dataset != "CCFs with lands") %>%
    group_by(dataset) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `Hamby comparisons`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to Hamby Comparisons (not sorted)"),
  all_pred %>%
    filter(dataset != "CCFs with lands") %>%
    group_by(dataset) %>%
    arrange(pred) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `Hamby comparisons`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to Hamby Comparisons (sorted)"),
  all_pred %>%
    filter(dataset != "Hamby comparisons") %>%
    group_by(dataset) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `CCFs with lands`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to CCFs with lands (not sorted)"), 
  all_pred %>%
    filter(dataset != "Hamby comparisons") %>%
    group_by(dataset) %>%
    arrange(pred) %>%
    mutate(case = 1:n()) %>%
    pivot_wider(names_from = "dataset", values_from = "pred") %>%
    ggplot(aes(x = `CCFs with lands`, y = internal)) +
    geom_point() + 
    theme(aspect.ratio = 1) +
    labs(title = "Comparing internal to CCFs with lands (sorted)")
)
```

# Training New Random Forests

## Try Old Seeds

The seeds used were selected by Heike based on ones she believes were used at the time of training `rtrees`.

Code for training random forest models based on the random forest fit in Eric's code found [here](https://github.com/erichare/imaging-paper/blob/master/code/full_run.R), which is believed to be the code used to train the original `rtrees`. 

```{r}
set.seed(20140501)
rtrees2 <-
  randomForest(
    factor(same_source) ~ ., 
    data = CCFs_withlands %>% select(rtrees_features, same_source), 
    ntree = 300
  )

set.seed(20170222)
rtrees3 <-
  randomForest(
    factor(same_source) ~ ., 
    data = CCFs_withlands %>% select(rtrees_features, same_source), 
    ntree = 300
  )
```

```{r}
set.seed(20170222)
rtrees4 <-
  randomForest(
    factor(same_source) ~ .,
    data = hamby_comparisons_filtered %>% select(rtrees_features, same_source),
    ntree = 300
  )

set.seed(20140501)
rtrees5 <-
  randomForest(
    factor(same_source) ~ .,
    data = hamby_comparisons_filtered %>% select(rtrees_features, same_source),
    ntree = 300
  )
```

```{r}
plot(rtrees2$votes, rtrees3$votes)
plot(rtrees2$votes, bulletxtrctr::rtrees$votes)
plot(rtrees3$votes, bulletxtrctr::rtrees$votes)
```

```{r}
plot(rtrees4$votes, rtrees5$votes)
plot(rtrees4$votes, bulletxtrctr::rtrees$votes)
plot(rtrees5$votes, bulletxtrctr::rtrees$votes)
```

```{r}
plot(sort(rtrees2$votes), sort(bulletxtrctr::rtrees$votes))
plot(sort(rtrees3$votes), sort(bulletxtrctr::rtrees$votes))
plot(sort(rtrees4$votes), sort(bulletxtrctr::rtrees$votes))
plot(sort(rtrees5$votes), sort(bulletxtrctr::rtrees$votes))
```

```{r}
bulletxtrctr::rtrees$confusion
rtrees2$confusion
rtrees3$confusion
rtrees4$confusion
rtrees5$confusion
```

## Distribution Across Seeds

Randomly select 100 seeds (using a random seed): 

```{r}
#set.seed(20200917)
set.seed(20200925)
seeds = sample(x = 10000000:100000000, size = 250, replace = FALSE)
seeds
```

Function for fitting random forests to mimic rtrees with different seeds:

```{r}
fit_rf <- function(seed, data) {
  set.seed(seed)
  bullet_rf <-
    randomForest(
      y = factor(data$same_source),
      x = data %>% select(all_of(rtrees_features)),
      ntree = bulletxtrctr::rtrees$ntree,
      mtry = bulletxtrctr::rtrees$mtry
    )
  return(bullet_rf)
}
```

Fit 250 new random forests and save or load:

```{r}
rfs_hamby_comparison_file = "../../../data/rfs_hamby_comparison.rds"
if (!file.exists(rfs_hamby_comparison_file)) {
  rfs_hamby_comparison = map(.x = seeds, .f = fit_rf, data = hamby_comparisons_filtered)
  saveRDS(object = bullet_rfs, file = rfs_hamby_comparison_file)
} else {
  rfs_hamby_comparison = readRDS(rfs_hamby_comparison_file)
}

rfs_CCFs_withlands_file = "../../../data/rfs_CCFs_withlands.rds"
if (!file.exists(rfs_CCFs_withlands_file)) {
  rfs_CCFs_withlands = map(.x = seeds, .f = fit_rf, data = CCFs_withlands)
  saveRDS(object = rfs_CCFs_withlands, file = rfs_CCFs_withlands_file)
} else {
  rfs_CCFs_withlands = readRDS(rfs_CCFs_withlands_file)
}
```

Function for extracting the confusion matrices from the model and put in a nice data frame:

```{r}
extract_confus <- function(model) {
  data.frame(model$confusion) %>%
    rename("FALSE" = "FALSE.", "TRUE" = "TRUE.", "class_error" = "class.error") %>%
    mutate(observed = rownames(model$confusion)) %>%
    pivot_wider(names_from = observed, values_from = everything())  
}
```

Extract the confusion matrices and importance values from all random forest models:

```{r}
hamby_comparison_confus <-
  map_df(.x = hamby_comparison_rfs, .f = extract_confus, .id = "rf_model_id")
CCFs_withlands_confus <-
  map_df(.x = CCFs_withlands_rfs, .f = extract_confus, .id = "rf_model_id")
```

Function for extracting the importance values, computing the rank of the features based on importance, and putting in a data frame: 

```{r}
extract_importance <- function(model) {
  data.frame(model$importance) %>%
    mutate(features = rownames(model$importance)) %>%
    arrange(desc(MeanDecreaseGini)) %>%
    mutate(rank = 1:n()) %>%
    rename("importance" = "MeanDecreaseGini") %>%
    select(features, importance, rank)
}
```

```{r}
hamby_comparison_importance <-
  map_df(.x = hamby_comparison_rfs, .f = extract_importance, .id = "rf_model_id")
CCFs_withlands_importance <-
  map_df(.x = CCFs_withlands_rfs, .f = extract_importance, .id = "rf_model_id")
```

### Visualizations of Class Errors

Obtain the class errors from `rtrees` and the paper random forest:

```{r}
rtrees_values <-
  data.frame(
    model = "rtrees",
    class_error_true = rtrees$confusion[2, 3],
    class_error_false = rtrees$confusion[1, 3]
  )
```

Histograms of the class errors (true and false) show that the rtrees values appear to be in the extreme (false) or outside of the new random forest models (true):

```{r fig.width = 10, fig.height = 4.5}
hist_true_hc <-
  hamby_comparison_confus %>%
  ggplot(aes(x = class_error_TRUE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_true, color = model))

hist_false_hc <- 
  CCFs_withlands_confus %>%
  ggplot(aes(x = class_error_FALSE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_false, color = model))

hist_true_ccfwl <-
  CCFs_withlands_confus %>%
  ggplot(aes(x = class_error_TRUE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_true, color = model))

hist_false_ccfwl <- 
  CCFs_withlands_confus %>%
  ggplot(aes(x = class_error_FALSE)) +
  geom_histogram() +
  geom_vline(data = rtrees_values,
             mapping = aes(xintercept = class_error_false, color = model))

plot_grid(hist_true_hc, hist_false_hc, hist_true_ccfwl, hist_false_ccfwl)
```

# LIME Explanation Comparison

# Session Info

```{r}
sessionInfo()
```
